faster	and	smarter.	It	is	fuelled	by	breakthroughs	in	the	life	sciences
	and	the
social	sciences	as	well.	The	better	we	understand	the	biochemical	mechanisms
that	underpin	human	emotions,	desires	and	choices,	the	better	computers	can
become	in	analysing	human	behaviour,	predicting	human	decisions,	and
replacing	human	drivers,	bankers	and	lawyers.
In	the	last	few	decades	research	in	areas	such	as	neuroscience	and	behavioural
economics	allowed	scientists	to	hack	humans,
	and	in	particular	to	gain	a	much
better	understanding	of	how	humans	make	decisions.	It	turned	out	that	our
choices	of	everything	from	food	to	mates	result	not	from	some	mysterious	free
will,	but	rather	from	billions	of	neurons	calculating	probabilities	within	a	split
second.	Vaunted	‘human	intuition’	is	in	reality	‘pattern	recognition’.
3
	Good
drivers,	bankers	and	lawyers	don’t	have	magical	intuitions
	about	traffic,
investment	or	negotiation	–	rather,	by	recognising	recurring	patterns,	they	spot
and	try	to	avoid	careless	pedestrians,	inept	borrowers	and	dishonest	crooks.	It
also	turned	out	that	the	biochemical	algorithms	of	the	human	brain	are	far	from
perfect.	They	rely	on	heuristics,	shortcuts	and	outdated	circuits	adapted	to	the
African	savannah	rather	than	to	the	urban	jungle.	No	wonder
	that	even	good
drivers,	bankers	and	lawyers	sometimes	make	stupid	mistakes.
This	means	that	AI	can	outperform	humans	even	in	tasks	that	supposedly
demand	‘intuition’.	If	you	think	AI	needs	to	compete	against	the	human	soul	in
terms	of	mystical	hunches	–	that	sounds	impossible.	But	if	AI	really	needs	to
compete	against	neural	networks	in	calculating	probabilities	and	recognising
patterns	–	that
	sounds	far	less	daunting.
In	particular,	AI	can	be	better	at	jobs	that	demand	intuitions	
about	other
people
.	Many	lines	of	work	–	such	as	driving	a	vehicle	in	a	street	full	of
pedestrians,	lending	money	to	strangers,	and	negotiating	a	business	deal	–
require	the	ability	to	correctly	assess	the	emotions	and	desires	of	other	people.	Is
that	kid	about	to	jump	onto	the	road?	Does	the	man	in	the	suit
	intend	to	take	my
money	and	disappear?	Will	that	lawyer	act	on	his	threats,	or	is	he	just	bluffing?
As	long	as	it	was	thought	that	such	emotions	and	desires	were	generated	by	an
immaterial	spirit,	it	seemed	obvious	that	computers	will	never	be	able	to	replace
human	drivers,	bankers	and	lawyers.	For	how	can	a	computer	understand	the
divinely	created	human	spirit?	Yet	if	these	emotions	and	desires
	are	in	fact	no
more	than	biochemical	algorithms,	there	is	no	reason	why	computers	cannot
decipher	these	algorithms	–	and	do	so	far	better	than	any	
Homo	sapiens
.
A	driver	predicting	the	intentions	of	a	pedestrian,	a	banker	assessing	the
credibility	of	a	potential	borrower,	and	a	lawyer	gauging	the	mood	at	the
negotiation	table	don’t	rely	on	witchcraft.	Rather,	unbeknownst	to	them,	their
brains
	are	recognising	biochemical	patterns	by	analysing	facial	expressions,tones	of	voice,	hand	movements,	and	even	body	odours.	An	AI	equipped	with
the	right	sensors	could	do	all	that	far	more	accurately	and	reliably	than	a	human.
Hence	the	threat	of	job	losses	does	not	result	merely	from	the	rise	of	infotech.
It	results	from	the	confluence	of	infotech	with	biotech.	The	way	from	the	fMRI
scanner
	to	the	labour	market	is	long	and	tortuous,	but	it	can	still	be	covered
within	a	few	decades.	What	brain	scientists	are	learning	today	about	the
amygdala	and	the	cerebellum	might	make	it	possible	for	computers	to
outperform	human	psychiatrists	and	bodyguards	in	2050.
AI	not	only	stands	poised	to	hack	humans	and	outperform	them	in	what	were
hitherto	uniquely	human	skills.	It	also	enjoys	uniquely
	non-human	abilities,
which	make	the	difference	between	an	AI	and	a	human	worker	one	of	kind
rather	than	merely	of	
degree.	Two	particularly	important	non-human	abilities
that	AI	possesses	are	connectivity	and	updateability.
Since	humans	are	individuals,	it	is	difficult	to	connect	them	to	one	another	and
to	make	sure	that	they	are	all	up	to	date.	In	contrast,	computers	aren’t
individuals,	and	it
	is	easy	to	integrate	them	into	a	single	flexible	network.	Hence
what	we	are	facing	is	not	the	replacement	of	millions	of	individual	human
workers	by	millions	of	individual	robots	and	computers.	Rather,	individual
humans	are	likely	to	be	replaced	by	an	integrated	network.	When	considering
automation	it	is	therefore	wrong	to	compare	the	abilities	of	a	single	human
driver	to	that	of	a	single	self-driving
	car,	or	of	a	single	human	doctor	to	that	of	a
single	AI	doctor.	Rather,	we	should	compare	the	abilities	of	a	collection	of
human	individuals	to	the	abilities	of	an	integrated	network.
For	example,	many	drivers	are	unfamiliar	with	all	the	changing	traffic
regulations,	and	they	often	violate	them.	In	addition,	since	every	vehicle	is	an
autonomous	entity,	when	two	vehicles	approach	the	same	junction
	at	the	same
time,	the	drivers	might	miscommunicate	their	intentions	and	collide.	Self-driving
cars,	in	contrast,	can	all	be	connected	to	one	another.	When	two	such	vehicles
approach	the	same	junction,	they	are	not	really	two	separate	entities	–	they	are
part	of	a	single	algorithm.	The	chances	that	they	might	miscommunicate	and
collide	are	therefore	far	smaller.	And	if	the	Ministry	of	Transport
	decides	to
change	some	traffic	regulation,	all	self-driving	vehicles	can	be	easily	updated	at
exactly	the	same	moment,	and	barring	some	bug	in	the	program,	they	will	all
follow	the	new	regulation	to	the	letter.
4
Similarly,	if	the	World	Health	Organization	identifies	a	new	disease,	or	if	a
laboratory	produces	a	new	medicine,	it	is	almost	impossible	to	update	all	the
human	doctors	in	the	world
	about	these	developments.	In	contrast,	even	if	you
have	10	billion	AI	doctors	in	the	world	–	each	monitoring	the	health	of	a	single
human	being	–	you	can	still	update	all	of	them	within	a	split	second,	and	theycan	all	communicate	to	each	other	their	feedback	on	the	new	disease	or
medicine.	These	potential	advantages	of	
connectivity	and	updateability	are	so
huge	that	at	least	in	some	lines	of
	work	it	might	make	sense	to	replace	
all
humans	with	computers,	even	if	individually	some	humans	still	do	a	better	job
than	the	machines.
You	might	object	that	by	switching	from	individual	humans	to	a	computer
network	we	will	lose	the	advantages	of	individuality.	For	example,	if	one	human
doctor	makes	a	wrong	judgement,	he	does	not	kill	all	the	patients	in	the	world,
and	he	does	not	block	the
	development	of	all	new	medications.	In	contrast,	if	all
doctors	are	really	just	a	single	system,	and	that	system	makes	a	mistake,	the
results	might	be	catastrophic.	In	truth,	however,	an	integrated	computer	system
can	maximise	the	advantages	of	connectivity	without	losing	the	benefits	of
individuality.	You	can	run	many	alternative	algorithms	on	the	same	network,	so
that	a	patient	in	a	remote	jungle
	village	can	access	through	her	smartphone	not
just	a	single	authoritative	doctor,	but	actually	a	hundred	different	AI	doctors,
whose	relative	performance	is	constantly	being	compared.	You	don’t	like	what
the	IBM	doctor	told	you?	No	problem.	Even	if	you	are	stranded	somewhere	on
the	slopes	of	Kilimanjaro,	you	can	easily	contact	the	Baidu	doctor	for	a	second
opinion.
The	benefits	for	human	society
	are	likely	to	be	immense.	AI	doctors	could
provide	far	better	and	cheaper	healthcare	for	billions	of	people,	particularly	for
those	who	currently	receive	no	healthcare	at	all.	Thanks	to	learning	algorithms
and	biometric	sensors,	a	poor	villager	in	an	underdeveloped	country	might	come
to	enjoy	far	better	healthcare	via	her	smartphone	than	the	richest	person	in	the
world	gets	today	from	the	most
	advanced	urban	hospital.
5
Similarly,	self-driving	vehicles	could	provide	people	with	much	better
transport	services,	and	in	particular	reduce	mortality	from	traffic	accidents.
Today	close	to	1.25	million	people	are	killed	annually	in	traffic	accidents	(twice
the	number	killed	by	war,	crime	and	terrorism	combined).
6
	More	than	90	per	cent
of	these	accidents	are	caused	by	very	human	errors:	somebody
	drinking	alcohol
and	driving,	somebody	texting	a	message	while	driving,	somebody	
falling	asleep
at	the	wheel,	somebody	daydreaming	instead	of	paying	attention	to	the	road.	The
US	National	Highway	Traffic	Safety	Administration	estimated	in	2012	that	31
per	cent	of	fatal	crashes	in	the	USA	involved	alcohol	abuse,	30	per	cent	involved
speeding,	and	21	per	cent	involved	distracted	drivers.
7
	Self-driving
	vehicles	will
never	do	any	of	these	things.	Though	they	suffer	from	their	own	problems	and
limitations,	and	though	some	accidents	are	inevitable,	replacing	all	human
drivers	by	computers	is	expected	to	reduce	deaths	and	injuries	on	the	road	by
about	90	per	cent.
8
	In	other	words,	switching	to	autonomous	vehicles	is	likely	tosave	the	lives	of	a	million	people	every	year.
Hence	it	would	be	madness
	to	block	automation	in	fields	such	as	transport	and
healthcare	just	in	order	to	protect	human	jobs.	After	all,	what	we	ultimately
ought	to	protect	is	humans	–	not	jobs.	Redundant	drivers	and	doctors	will	just
have	to	find	something	else	to	do.
The	Mozart	in	the	machine
At	least	in	the	short	term,	AI	and	robotics	are	unlikely	to	completely	eliminate
entire	industries.	Jobs	that	require	specialisation
	in	a	narrow	range	of	routinised
activities	will	be	automated.	But	it	will	be	much	more	difficult	to	replace
humans	with	machines	in	less	routine	jobs	that	demand	the	simultaneous	use	of	a
wide	range	of	skills,	and	that	involve	dealing	with	unforeseen	scenarios.	Take
healthcare,	for	example.	Many	doctors	focus	almost	exclusively	on	processing
information:	they	absorb	medical	data,	analyse	it,
	and	produce	a	diagnosis.
Nurses,	in	contrast,	also	need	good	motor	and	emotional	skills	in	order	to	give	a
painful	injection,	replace	a	bandage,	or	restrain	a	violent	patient.	Hence	we	will
probably	have	an	AI	family	doctor	on	our	smartphone	decades	before	we	have	a
reliable	nurse	robot.
9
	The	human	care	industry	–	which	takes	care	of	the	sick,	the
young	and	the	elderly	–	is	likely	to	remain	a
	human	bastion	for	a	long	time.
Indeed,	as	people	live	
longer	and	have	fewer	children,	care	of	the	elderly	will
probably	be	one	of	the	fastest-growing	sectors	in	the	human	labour	market.
Alongside	care,	creativity	too	poses	particularly	difficult	hurdles	for
automation.	We	don’t	need	humans	to	sell	us	music	any	more	–	we	can
download	it	directly	from	the	iTunes	store	–	but	the	composers,	musicians,
singers	and	DJs	are	still	flesh	and	blood.	We	rely	on	their	creativity	not	just	to
produce	completely	new	music,	but	also	to	choose	among	a	mind-boggling	range
of	available	possibilities.
Nevertheless,	in	the	long	run	no	job	will	remain	absolutely	safe	from
automation.	Even	artists	should	be	put	on	notice.	In	the	modern	world	art	is
usually	associated	with	human	emotions.	We	tend	to	think	that
	artists	are
channelling	internal	psychological	forces,	and	that	the	whole	purpose	of	art	is	to
connect	us	with	our	emotions	or	to	inspire	in	us	some	new	feeling.
Consequently,	when	we	come	to	evaluate	art,	we	tend	to	judge	it	by	its
emotional	impact	on	the	audience.	Yet	if	art	is	defined	by	human	emotions,	what
might	happen	once	external	algorithms	are	able	to	understand	and	manipulate
human	emotions
	better	than	Shakespeare,	Frida	Kahlo	or	Beyoncé?After	all,	emotions	are	not	some	mystical	phenomenon	–	they	are	the	result	of
a	biochemical	process.	Hence,	in	the	not	too	distant	future	a	machine-learning
algorithm	could	analyse	the	biometric	data	streaming	from	sensors	on	and	inside
your	body,	determine	your	personality	type	and	your	changing	moods,	and
calculate	the	emotional	impact	that	a
	particular	song	–	even	a	particular	musical
key	–	is	likely	to	have	on	you.
10
Of	all	forms	of	art,	music	is	probably	the	most	susceptible	to	Big	Data
analysis,	because	both	inputs	and	outputs	lend	themselves	to	precise
mathematical	depiction.	The	inputs	are	the	mathematical	patterns	of	sound
waves,	and	the	outputs	are	the	electrochemical	patterns	of	neural	storms.	Within
a	few	decades,	an	algorithm
	that	goes	over	millions	of	musical	experiences
might	learn	to	predict	how	particular	inputs	result	in	particular	outputs.
11
Suppose	you	just	had	a	nasty	fight	with	your	boyfriend.	The	algorithm	in
charge	of	your	sound	system	will	immediately	discern	your	inner	emotional
turmoil,	and	based	on	what	it	knows	about	you	personally	and	about	human
psychology	in	general,	it	will	play	songs	tailored
	to	resonate	with	your	gloom
and	echo	your	distress.	These	particular	songs	might	not	work	well	with	other
people,	but	are	just	perfect	for	your	personality	type.	After	helping	you	get	in
touch	with	the	depths	of	your	sadness,	the	algorithm	would	then	play	the	one
song	in	the	world	that	is	likely	to	cheer	you	up	–	perhaps	because	your
subconscious	connects	it	with	a	happy	childhood	memory	that	even
	you	are	not
aware	of.	No	human	DJ	could	ever	hope	to	match	the	skills	of	such	an	AI.
You	might	object	that	the	AI	would	thereby	kill	serendipity	and	lock	us	inside
a	narrow	musical	cocoon,	woven	by	our	previous	likes	and	dislikes.	What	about
exploring	new	musical	tastes	and	styles?	No	problem.	You	could	easily	adjust
the	algorithm	to	make	5	per	cent	of	its	choices	completely	at	random,
unexpectedly
	throwing	at	you	a	recording	of	an	Indonesian	Gamelan	ensemble,	a
Rossini	opera,	or	the	latest	K-pop	hit.	Over	time,	by	monitoring	your	reactions,
the	AI	could	even	determine	the	ideal	level	of	randomness	that	will	optimise
exploration	while	avoiding	annoyance,	perhaps	lowering	its	serendipity	level	to
3	per	cent	or	raising	it	to	8	per	cent.
Another	possible	objection	is	that	it	is	unclear	how
	the	algorithm	could
establish	its	emotional	goal.	If	you	just	fought	with	your	boyfriend,	should	the
algorithm	aim	to	make	you	sad	or	joyful?	Would	it	blindly	follow	a	rigid	scale	of
‘good’	emotions	and	‘bad’	emotions?	Maybe	there	are	times	in	life	when	it	is
good	to	feel	sad?	The	same	question,	of	course,	could	be	directed	at	human
musicians	and	DJs.	Yet	with	an	algorithm,	there	are	many	interesting
	solutions
to	this	puzzle.
One	option	is	to	just	leave	it	to	the	customer.	You	can	evaluate	your	emotionswhichever	way	you	like,	and	the	algorithm	will	follow	your	dictates.	Whether
you	want	to	wallow	in	self-pity	or	jump	for	joy,	the	algorithm	will	slavishly
follow	your	lead.	Indeed,	
the	algorithm	may	learn	to	recognise	your	wishes	even
without	you	being	explicitly	aware	of	them.
Alternatively,
	if	you	don’t	trust	yourself,	you	can	instruct	the	algorithm	to
follow	the	recommendation	of	whichever	eminent	psychologist	you	do	trust.	If
your	boyfriend	eventually	dumps	you,	the	algorithm	may	walk	you	through	the
official	five	stages	of	grief,	first	helping	you	deny	what	happened	by	playing
Bobby	McFerrin’s	‘Don’t	Worry,	Be	Happy’,	then	whipping	up	your	anger	with
Alanis	Morissette’s	‘You
	Oughta	Know’,	encouraging	you	to	bargain	with
Jacques	Brel’s	‘Ne	me	quitte	pas’	and	Paul	Young’s	‘Come	Back	and	Stay’,
dropping	you	into	the	pit	of	depression	with	Adele’s	‘Someone	Like	You’	and
‘Hello’,	and	finally	aiding	you	to	accept	the	situation	with	Gloria	Gaynor’s	‘I
Will	Survive’.
The	next	step	is	for	the	algorithm	to	start	tinkering	with	the	songs	and
melodies	themselves,	changing	them
	ever	so	slightly	to	fit	your	quirks.	Perhaps
you	dislike	a	particular	bit	in	an	otherwise	excellent	song.	The	algorithm	knows
it	because	your	heart	skips	a	beat	and	your	oxytocin	levels	drop	slightly
whenever	you	hear	that	annoying	part.	The	algorithm	could	rewrite	or	edit	out
the	offending	notes.
In	the	long	run,	algorithms	may	learn	how	to	compose	entire	tunes,	playing	on
human	emotions	as
	if	they	were	a	piano	keyboard.	Using	your	biometric	data	the
algorithms	could	even	produce	personalised	melodies,	which	you	alone	in	the
entire	universe	would	appreciate.
It	is	often	said	that	people	connect	with	art	because	they	find	themselves	in	it.
This	may	lead	to	surprising	and	somewhat	sinister	results	if	and	when,	say,
Facebook	begins	creating	personalised	art	based	on	everything	it	knows
	about
you.	If	your	boyfriend	leaves	you,	Facebook	will	treat	you	to	an	individualised
song	about	that	particular	bastard	rather	than	about	the	unknown	person	who
broke	the	heart	of	Adele	or	Alanis	Morissette.	The	song	will	even	remind	you	of
real	incidents	from	your	relationship,	which	nobody	else	in	the	world	knows
about.
Of	course,	personalised	art	might	never	catch	on,	because	people	will
	continue
to	prefer	common	hits	that	everybody	likes.	How	can	you	dance	or	sing	together
to	a	tune	nobody	besides	you	knows?	But	algorithms	could	prove	even	more
adept	at	producing	global	hits	than	personalised	rarities.	By	using	massive
biometric	databases	garnered	from	millions	of	people,	the	algorithm	could	know
which	biochemical	buttons	to	press	in	order	to	produce	a	global	hit	which	would
set
	everybody	swinging	like	crazy	on	the	dance	floors.	If	art	is	really	aboutinspiring	(or	manipulating)	human	emotions,	few	if	any	human	musicians	will
have	a	chance	of	competing	with	such	an	algorithm,	because	they	cannot	match
it	in	understanding	the	chief	instrument	they	are	playing	on:	the	human
biochemical	system.
Will	all	this	result	in	great	art?	That	depends	on	the	definition	of	art.	If
	beauty
is	indeed	in	the	ears	of	the	listener,	and	if	the	customer	is	always	right,	then
biometric	algorithms	stand	a	chance	of	producing	the	best	art	in	history.	If	art	is
about	something	deeper	than	human	emotions,	and	should	express	a	truth
beyond	our	biochemical	vibrations,	biometric	algorithms	might	not	make	very
good	artists.	But	nor	do	most	humans.	In	order	to	enter	the	art	market	and
displace
	many	human	composers	and	performers,	algorithms	won’t	have	to
begin	by	straightaway	surpassing	Tchaikovsky.	It	will	be	enough	if	they
outperform	Britney	Spears.
New	jobs?
The	loss	of	many	traditional	jobs	in	everything	from	art	to	healthcare	will	partly
be	offset	by	the	creation	of	new	human	jobs.	GPs	who	focus	on	diagnosing
known	diseases	and	administering	familiar	treatments	will	probably	be
	replaced
by	AI	doctors.	But	precisely	because	of	that,	there	will	be	much	more	money	to
pay	human	doctors	and	lab	assistants	to	do	groundbreaking	research	and	develop
new	medicines	or	surgical	procedures.
12
AI	might	help	create	new	human	jobs	in	another	way.	Instead	of	humans
competing	with	AI,	they	could	focus	on	servicing	and	leveraging	AI.	For
example,	the	replacement	of	human	pilots	by	drones
	has	eliminated	some	jobs
but	created	many	new	opportunities	in	maintenance,	remote	control,	data
analysis	and	cyber	security.	The	US	armed	forces	need	thirty	people	to	operate
every	unmanned	Predator	or	Reaper	drone	flying	over	Syria,	while	analysing	the
resulting	harvest	of	information	occupies	at	least	eighty	people	more.	In	2015
the	US	Air	Force	lacked	sufficient	trained	humans	to	fill	all
	these	positions,	and
therefore	faced	an	ironic	crisis	in	manning	its	unmanned	aircraft.
13
If	so,	the	job	market	of	2050	might	well	be	characterised	by	human–AI
cooperation	rather	than	competition.	In	fields	ranging	from	policing	to	banking,
teams	of	humans-plus-AIs	could	outperform	both	humans	and	computers.	After
IBM’s	chess	program	Deep	Blue	beat	Garry	Kasparov	in	1997,	humans	did	not
stop
	playing	chess.	Rather,	thanks	to	AI	trainers	human	chess	masters	became
better	than	ever,	and	at	least	for	a	while	human–AI	teams	known	as	‘centaurs’outperformed	both	humans	and	computers	in	chess.	AI	might	similarly	help
groom	the	best	detectives,	bankers	and	soldiers	in	history.
14
The	problem	with	all	such	new	jobs,	however,	is	that	they	will	probably
demand	high	levels	of	expertise,	and	will
	therefore	not	solve	the	problems	of
unemployed	unskilled	labourers.	Creating	new	human	jobs	might	prove	easier
than	retraining	humans	to	actually	fill	these	jobs.	During	previous	waves	of
automation,	people	could	usually	switch	from	one	routine	low-skill	job	to
another.	In	1920	a	farm	worker	laid	off	due	to	the	mechanisation	of	agriculture
could	find	a	new	job	in	a	factory	producing	tractors.
	In	1980	an	unemployed
factory	worker	could	start	working	as	a	cashier	in	a	supermarket.	Such
occupational	changes	were	feasible,	because	the	move	from	the	farm	to	the
factory	and	from	the	factory	to	the	supermarket	required	only	limited	retraining.
But	in	2050,	a	cashier	or	textile	worker	losing	their	job	to	a	robot	will	hardly
be	able	to	start	working	as	a	cancer	researcher,	as	
a	drone	operator,
	or	as	part	of
a	human–AI	banking	team.	They	will	not	have	the	necessary	skills.	In	the	First
World	War	it	made	sense	to	send	millions	of	raw	conscripts	to	charge	machine
guns	and	die	in	their	thousands.	Their	individual	skills	mattered	little.	Today,
despite	the	shortage	of	drone	operators	and	data	analysts,	the	US	Air	Force	is
unwilling	to	fill	the	gaps	with	Walmart	dropouts.	You	wouldn’t	like
	an
inexperienced	recruit	to	mistake	an	Afghan	wedding	party	for	a	high-level
Taliban	conference.
Consequently,	despite	the	appearance	of	many	new	human	jobs,	we	might
nevertheless	witness	the	rise	of	a	new	‘useless’	class.	We	might	actually	get	the
worst	of	both	worlds,	suffering	simultaneously	from	high	unemployment	and	a
shortage	of	skilled	labour.	Many	people	might	share	the	fate	not	of	nineteenth-
century
	wagon	drivers	–	who	switched	to	driving	taxis	–	but	of	nineteenth-
century	horses,	who	were	increasingly	pushed	out	of	the	job	market	altogether.
15
In	addition,	no	remaining	human	job	will	ever	be	safe	from	the	threat	of	future
automation,	because	machine	learning	and	robotics	will	continue	to	improve.	A
forty-year-old	unemployed	Walmart	cashier	who	by	dint	of	superhuman	efforts
manages	to	reinvent
	herself	as	a	drone	pilot	might	have	to	reinvent	herself	again
ten	years	later,	because	by	then	the	flying	of	drones	may	also	have	been
automated.	This	volatility	will	also	make	it	more	difficult	to	organise	unions	or
secure	labour	rights.	Already	today,	many	new	jobs	in	advanced	economies
involve	unprotected	temporary	work,	freelancing	and	one-time	gigs.
16
	How	do
you	unionise	a	profession	that
	mushrooms	and	disappears	within	a	decade?
Similarly,	human–computer	centaur	teams	are	likely	to	be	characterised	by	a
constant	tug	of	war	between	the	humans	and	the	computers,	instead	of	settling
down	to	a	lifelong	partnership.	Teams	made	exclusively	of	humans	–	such	asSherlock	Holmes	and	Dr	Watson	–	usually	develop	permanent	hierarchies	and
routines	that	last	decades.	But	a	human	detective
	who	teams	up	with	IBM’s
Watson	computer	system	(which	became	famous	after	winning	the	US	TV	quiz
show	
Jeopardy!
	in	2011)	will	find	that	every	
routine	is	an	invitation	for
disruption,	and	every	hierarchy	an	invitation	for	revolution.	Yesterday’s	sidekick
might	morph	into	tomorrow’s	superintendent,	and	all	protocols	and	manuals	will
have	to	be	rewritten	every	year.
17
A	closer	look	at	the	world
	of	chess	might	indicate	where	things	are	heading	in
the	long	run.	It	is	true	that	for	several	years	after	Deep	Blue	defeated	Kasparov,
human–computer	cooperation	flourished	in	chess.	Yet	in	recent	years	computers
have	become	so	good	at	playing	chess	that	their	human	collaborators	lost	their
value,	and	might	soon	become	utterly	irrelevant.
On	7	December	2017	a	critical	milestone	was	reached,	not
	when	a	computer
defeated	a	human	at	chess	–	that’s	old	news	–	but	when	Google’s	AlphaZero
program	defeated	the	Stockfish	8	program.	Stockfish	8	was	the	world’s
computer	chess	champion	for	2016.	It	had	access	to	centuries	of	accumulated
human	experience	in	chess,	as	well	as	to	decades	of	computer	experience.	It	was
able	to	calculate	70	million	chess	positions	per	second.	In	contrast,	AlphaZero
performed
	only	80,000	such	calculations	per	second,	and	its	human	creators
never	taught	it	any	chess	strategies	–	not	even	standard	openings.	Rather,
AlphaZero	used	the	latest	machine-learning	principles	to	self-learn	chess	by
playing	against	itself.	Nevertheless,	out	of	a	hundred	games	the	novice
AlphaZero	played	against	Stockfish,	AlphaZero	won	twenty-eight	and	tied
seventy-two.	It	didn’t	lose	even
	once.	Since	AlphaZero	learned	nothing	from	any
human,	many	of	its	winning	moves	and	strategies	seemed	unconventional	to
human	eyes.	They	may	well	be	considered	creative,	if	not	downright	genius.
Can	you	guess	how	long	it	took	AlphaZero	to	learn	chess	from	scratch,
prepare	for	the	match	against	Stockfish,	and	develop	its	genius	instincts?	Four
hours.	That’s	not	a	typo.	For	centuries,	chess	was
	considered	one	of	the
crowning	glories	of	human	intelligence.	AlphaZero	went	from	utter	ignorance	to
creative	mastery	in	four	hours,	without	the	help	of	any	human	guide.
18
AlphaZero	is	not	the	only	imaginative	software	out	there.	Many	programs
now	routinely	outperform	human	chess	players	
not	just	in	brute	calculation,	but
even	in	‘creativity’.	In	human-only	chess	tournaments,	judges	are	constantly
	on
the	lookout	for	players	who	try	to	cheat	by	secretly	getting	help	from	computers.
One	of	the	ways	to	catch	cheats	is	to	monitor	the	level	of	originality	players
display.	If	they	play	an	exceptionally	creative	move,	the	judges	will	often
suspect	that	this	cannot	possibly	be	a	human	move	–	it	must	be	a	computer
move.	At	least	in	chess,	creativity	is	already	the	trademark	of	computers	ratherthan	humans!	Hence	if	chess	is	our	coal-mine	canary,	we	are	duly	warned	that
the	canary	is	dying.	What	is	happening	today	to	human–AI	chess	teams	might
happen	down	the	road	to	human–AI	teams	in	policing,	medicine	and	banking
too.
19
Consequently,	creating	new	jobs	and	retraining	people	to	fill	them	will	not	be
a	one-off	effort.	The	AI	revolution	won’t	be	a	single	watershed	event	after	which
the
	job	market	will	just	settle	into	a	new	equilibrium.	Rather,	it	will	be	a	cascade
of	ever-bigger	disruptions.	Already	today	few	employees	expect	to	work	in	the
same	job	for	their	entire	life.
20
	By	2050,	not	just	the	idea	of	‘a	job	for	life’,	but
even	the	idea	of	‘a	profession	for	life’	might	seem	antediluvian.
Even	if	we	could	constantly	invent	new	jobs	and	retrain	the	workforce,	we
may	wonder
	whether	the	average	human	will	have	the	emotional	stamina
necessary	for	a	life	of	such	endless	upheavals.	Change	is	always	stressful,	and
the	hectic	world	of	the	early	twenty-first	century	has	produced	a	global	epidemic
of	stress.
21
	As	the	volatility	of	the	job	market	and	of	individual	careers	increases,
would	people	be	able	to	cope?	We	would	probably	need	far	more	effective
stress-reduction	techniques
	–	ranging	from	drugs	through	neuro-feedback	to
meditation	–	to	prevent	the	Sapiens	mind	from	snapping.	By	2050	a	‘useless’
class	might	emerge	not	merely	because	of	an	absolute	lack	of	jobs	or	lack	of
relevant	education,	but	also	because	of	insufficient	mental	stamina.
Obviously,	most	of	this	is	just	speculation.	At	the	time	of	writing	–	early	2018
–	automation	has	disrupted	many	industries	but
	it	has	not	resulted	in	massive
unemployment.	In	fact,	in	many	
countries,	such	as	the	USA,	unemployment	is	at
a	historical	low.	Nobody	can	know	for	sure	what	sort	of	impact	machine	learning
and	automation	will	have	on	different	professions	in	the	future,	and	it	is
extremely	difficult	to	estimate	the	timetable	of	relevant	developments,	especially
as	they	depend	on	political	decisions	and	cultural
	traditions	as	much	as	on	purely
technological	breakthroughs.	Thus	even	after	self-driving	vehicles	prove
themselves	safer	and	cheaper	than	human	drivers,	politicians	and	consumers
might	nevertheless	block	the	change	for	years,	perhaps	decades.
However,	we	cannot	allow	ourselves	to	be	complacent.	It	is	dangerous	just	to
assume	that	enough	new	jobs	will	appear	to	compensate	for	any	losses.	The
	fact
that	this	has	happened	during	previous	waves	of	automation	is	absolutely	no
guarantee	that	it	will	happen	again	under	the	very	different	conditions	of	the
twenty-first	century.	The	potential	social	and	political	disruptions	are	so
alarming	that	even	if	the	probability	of	systemic	mass	unemployment	is	low,	we
should	take	it	very	seriously.
In	the	nineteenth	century	the	Industrial	Revolution
	created	new	conditions	and
problems	that	none	of	the	existing	social,	economic	and	political	models	couldcope	with.	Feudalism,	monarchism	and	traditional	religions	were	not	adapted	to
managing	industrial	metropolises,	millions	of	uprooted	workers,	or	the
constantly	changing	nature	of	the	modern	economy.	Consequently	humankind
had	to	develop	completely	new	models	–	liberal	democracies,	communist
dictatorships	and	fascist	regimes	–	and	it	took	more	than	a	century	of	terrible
wars	and	revolutions	to	experiment	with	these	models,	separate	the	wheat	from
the	chaff,	and	implement	the	best	solutions.	Child	labour	in	Dickensian	coal
mines,	the	First	World	War	and	the	Great	Ukrainian	Famine	of	1932–3
constituted	just	a	small	part	of	the	tuition	fees	humankind	paid.
The	challenge	posed	to	humankind
	in	the	twenty-first	century	by	infotech	and
biotech	is	arguably	much	bigger	than	the	challenge	posed	in	the	previous	era	by
steam	engines,	railroads	and	electricity.	And	given	the	immense	destructive
power	of	our	
civilisation,	we	just	cannot	afford	more	failed	models,	world	wars
and	bloody	revolutions.	This	time	around,	the	failed	models	might	result	in
nuclear	wars,	genetically	engineered	monstrosities,
	and	a	complete	breakdown
of	the	biosphere.	Consequently,	we	have	to	do	better	than	we	did	in	confronting
the	Industrial	Revolution.
From	exploitation	to	irrelevance
Potential	solutions	fall	into	three	main	categories:	what	to	do	in	order	to	prevent
jobs	from	being	lost;	what	to	do	in	order	to	create	enough	new	jobs;	and	what	to
do	if,	despite	our	best	efforts,	job	losses	significantly	outstrip
	job	creation.
Preventing	job	losses	altogether	is	an	unattractive	and	probably	untenable
strategy,	because	it	means	giving	up	the	immense	positive	potential	of	AI	and
robotics.	Nevertheless,	governments	might	decide	to	deliberately	slow	down	the
pace	of	automation,	in	order	to	lessen	the	resulting	shocks	and	allow	time	for
readjustments.	Technology	is	never	deterministic,	and	the	fact	that	something
can	be	done	does	not	mean	it	must	be	done.	Government	regulation	can
successfully	block	new	technologies	even	if	they	are	commercially	viable	and
economically	lucrative.	For	example,	for	many	decades	we	have	had	the
technology	to	create	a	marketplace	for	human	organs,	complete	with	human
‘body	farms’	in	underdeveloped	countries	and	an	almost	insatiable	demand	from
desperate	affluent	buyers.
	Such	body	farms	could	well	be	worth	hundreds	of
billions	of	dollars.	Yet	regulations	have	prevented	free	trade	in	human	body
parts,	and	though	there	is	a	black	market	in	organs,	it	is	far	smaller	and	more
circumscribed	than	what	one	could	have	expected.
22Slowing	down	the	pace	of	change	may	give	us	time	to	create	enough	new	jobs
to	replace	most	of	the	losses.	Yet	as	noted	earlier,	economic	entrepreneurship
will	have	to	be	accompanied	by	a	revolution	in	education	and	psychology.
Assuming	that	the	new	jobs	won’t	be	just	government	sinecures,	they	will
probably	demand	
high	levels	of	expertise,	and	as	AI	continues	to	improve,
human	employees	will	need	to	repeatedly	learn	new	skills	and	change	their
profession.	Governments	will	have	to	step	in,	both	by	subsidising	a	lifelong
education	sector,	and	by
	providing	a	safety	net	for	the	inevitable	periods	of
transition.	If	a	forty-year-old	ex-drone	pilot	takes	three	years	to	reinvent	herself
as	a	designer	of	virtual	worlds,	she	may	well	need	a	lot	of	government	help	to
sustain	herself	and	her	family	during	that	time.	(This	kind	of	scheme	is	currently
being	pioneered	in	Scandinavia,	where	governments	follow	the	motto	‘protect
workers,	not	jobs’.)
Yet	even	if	enough	government	help	is	forthcoming,	it	is	far	from	clear
whether	billions	of	people	could	repeatedly	reinvent	themselves	without	losing
their	mental	balance.	Hence,	if	despite	all	our	efforts	a	significant	percentage	of
humankind	is	pushed	out	of	the	job	market,	we	would	have	to	explore	new
models	for	post-work	societies,	post-work	economies,	and	post-work	politics.
The	first	step
	is	to	honestly	acknowledge	that	the	social,	economic	and	political
models	we	have	inherited	from	the	past	are	inadequate	for	dealing	with	such	a
challenge.
Take,	for	example,	communism.	As	automation	threatens	to	shake	the
capitalist	system	to	its	foundation,	one	might	suppose	that	communism	could
make	a	comeback.	But	communism	was	not	built	to	exploit	that	kind	of	crisis.
Twentieth-century	communism
	assumed	that	the	working	class	was	vital	for	the
economy,	and	communist	thinkers	tried	to	teach	the	proletariat	how	to	translate
its	immense	economic	power	into	political	clout.	The	communist	political	plan
called	for	a	working-class	revolution.	How	relevant	will	these	teachings	be	if	the
masses	lose	their	economic	value,	and	therefore	need	to	struggle	against
irrelevance	rather	than	against
	exploitation?	How	do	you	start	a	working-class
revolution	without	a	working	class?
Some	may	argue	that	humans	could	never	become	economically	irrelevant,
because	even	if	they	cannot	compete	with	AI	in	the	workplace,	they	will	always
be	needed	as	consumers.	However,	it	is	far	from	certain	that	the	future	economy
will	need	us	
even	as	consumers.	Machines	and	computers	could	do	that	too.
Theoretically,
	you	can	have	an	economy	in	which	a	mining	corporation	produces
and	sells	iron	to	a	robotics	corporation,	the	robotics	corporation	produces	and
sells	robots	to	the	mining	corporation,	which	mines	more	iron,	which	is	used	to
produce	more	robots,	and	so	on.	These	corporations	can	grow	and	expand	to	thefar	reaches	of	the	galaxy,	and	all	they	need	are	robots	and	computers	–	they
don’t	need	humans
	even	to	buy	their	products.
Indeed,	already	today	computers	and	algorithms	are	beginning	to	function	as
clients	in	addition	to	producers.	In	the	stock	exchange,	for	example,	algorithms
are	becoming	the	most	important	buyers	of	bonds,	shares	and	commodities.
Similarly	in	the	advertisement	business,	the	most	important	customer	of	all	is	an
algorithm:	the	Google	search	algorithm.	When	people	design
	Web	pages,	they
often	cater	to	the	taste	of	the	Google	search	algorithm	rather	than	to	the	taste	of
any	human	being.
Algorithms	obviously	have	no	consciousness,	so	unlike	human	consumers,
they	cannot	enjoy	what	they	buy,	and	their	decisions	are	not	shaped	by
sensations	and	emotions.	The	Google	search	algorithm	cannot	taste	ice	cream.
However,	algorithms	select	things	based	on	their	internal	calculations
	and	built-
in	preferences,	and	these	preferences	increasingly	shape	our	world.	The	Google
search	algorithm	has	a	very	sophisticated	taste	when	it	comes	to	ranking	the
Web	pages	of	ice-cream	vendors,	and	the	most	successful	ice-cream	vendors	in
the	world	are	those	that	the	Google	algorithm	ranks	first	–	not	those	that	produce
the	tastiest	ice	cream.
I	know	this	from	personal	experience.	When	I
	publish	a	book,	the	publishers
ask	me	to	write	a	short	description	that	they	use	for	publicity	online.	But	they
have	a	special	expert,	who	adapts	what	I	write	to	the	taste	of	the	Google
algorithm.	The	expert	goes	over	my	text,	and	says	‘Don’t	use	this	word	–	use
that	word	instead.	Then	we	will	get	more	attention	from	the	Google	algorithm.’
We	know	that	if	we	can	just	catch	the	eye	of	the	algorithm,
	we	can	take	the
humans	for	granted.
So	if	humans	are	needed	neither	as	producers	nor	as	consumers,	what	will
safeguard	their	physical	survival	and	their	psychological	well-being?	We	cannot
wait	for	the	crisis	to	erupt	in	full	force	before	we	start	looking	for	answers.	By
then	it	will	be	too	late.	In	order	to	cope	with	the	unprecedented	technological
and	economic	disruptions	of	the	twenty-first
	century,	we	need	to	develop	new
social	and	economic	models	as	soon	as	possible.	These	models	should	be	guided
by	the	principle	of	protecting	humans	rather	than	jobs.	Many	jobs	are
uninspiring	drudgery,	not	worth	saving.	Nobody’s	life-dream	is	to	be	a	cashier.
What	we	should	focus	on	is	providing	for	people’s	basic	needs	and	protecting
their	social	status	and	self-worth.
One	new	model,	which	is
	gaining	increasing	attention,	is	universal	basic
income.	UBI	proposes	that	governments	tax	the	billionaires	and	corporations
controlling	the	algorithms	and	robots,	and	use	the	money	to	provide	every
person	with	a	generous	stipend	covering	his	or	her	basic	needs.	This	will	cushionthe	poor	against	job	loss	and	economic	dislocation,	while	protecting	the	rich
from	populist	rage.
23
	A	related	idea
	proposes	to	widen	the	range	of	human
activities	that	are	considered	to	be	‘jobs’.	At	present,	billions	of	parents	take	care
of	children,	neighbours	look	after	one	another,	and	citizens	organise
communities,	without	any	of	these	valuable	activities	being	recognised	as	jobs.
Maybe	we	need	to	turn	a	switch	in	our	minds,	and	realise	that	taking	care	of	a
child	is	arguably	the	most	important	and	challenging
	job	in	the	world.	If	so,	there
won’t	be	a	shortage	of	work	even	if	computers	and	robots	replace	all	the	drivers,
bankers	and	lawyers.	The	question	is,	of	course,	who	would	evaluate	and	pay	for
these	newly	recognised	jobs?	Assuming	that	six-month-old	babies	will	not	pay	a
salary	to	their	mums,	the	government	will	probably	have	to	take	this	upon	itself.
Assuming,	too,	that	we	will	like	these	salaries
	to	cover	all	of	a	family’s	basic
needs,	the	end	result	will	be	something	that	is	not	very	different	from	universal
basic	income.
Alternatively,	governments	could	subsidise	universal	basic	
services
	rather
than	income.	Instead	of	giving	money	to	people,	
who	then	shop	around	for
whatever	they	want,	the	government	might	subsidise	free	education,	free
healthcare,	free	transport	and	so	forth.	This
	is	in	fact	the	utopian	vision	of
communism.	Though	the	communist	plan	to	start	a	working-class	revolution
might	well	become	outdated,	maybe	we	should	still	aim	to	realise	the	communist
goal	by	other	means?
It	is	debatable	whether	it	is	better	to	provide	people	with	universal	basic
income	(the	capitalist	paradise)	or	universal	basic	services	(the	communist
paradise).	Both	options	have	advantages
	and	drawbacks.	But	no	matter	which
paradise	you	choose,	the	real	problem	is	in	defining	what	‘universal’	and	‘basic’
actually	mean.
What	is	universal?
When	people	speak	about	universal	basic	support	–	whether	in	the	shape	of
income	or	services	–	they	usually	mean	
national
	basic	support.	Hitherto,	all	UBI
initiatives	have	been	strictly	national	or	municipal.	In	January	2017,	Finland
began	a	two-year
	experiment,	providing	2,000	unemployed	Finns	with	560	euros
a	month,	irrespective	of	whether	they	find	work	or	not.	Similar	experiments	are
under	way	in	the	Canadian	province	of	Ontario,	in	the	Italian	city	of	Livorno,
and	in	several	Dutch	cities.
24
	(In	2016	Switzerland	held	a	referendum	on
instituting	a	national	basic	income	scheme,	but	voters	rejected	the	idea.
25
)The	problem	with	such	national
	and	municipal	schemes,	however,	is	that	the
main	victims	of	automation	may	not	live	in	Finland,	Ontario,	Livorno	or
Amsterdam.	Globalisation	has	made	people	in	one	country	utterly	dependent	on
markets	in	other	countries,	but	automation	might	unravel	large	parts	of	this
global	trade	network	with	disastrous	consequences	for	the	weakest	links.	In	the
twentieth	century,	developing	countries	lacking
	natural	resources	made
economic	progress	mainly	by	selling	the	cheap	labour	of	their	unskilled	workers.
Today	millions	of	Bangladeshis	make	a	living	by	producing	shirts	and	selling
them	to	customers	
in	the	United	States,	while	people	in	Bangalore	earn	their
keep	in	call	centres	dealing	with	the	complaints	of	American	customers.
26
Yet	with	the	rise	of	AI,	robots	and	3-D	printers,	cheap	unskilled
	labour	would
become	far	less	important.	Instead	of	manufacturing	a	shirt	in	Dhaka	and
shipping	it	all	the	way	to	the	US,	you	could	buy	the	shirt’s	code	online	from
Amazon,	and	print	it	in	New	York.	The	Zara	and	Prada	stores	on	Fifth	Avenue
could	be	replaced	by	3-D	printing	centres	in	Brooklyn,	and	some	people	might
even	have	a	printer	at	home.	Simultaneously,	instead	of	calling	customer
services
	in	Bangalore	to	complain	about	your	printer,	you	could	talk	with	an	AI
representative	in	the	Google	cloud	(whose	accent	and	tone	of	voice	are	tailored
to	your	preferences).	The	newly	unemployed	workers	and	call-centre	operators
in	Dhaka	and	Bangalore	don’t	have	the	education	necessary	to	switch	to
designing	fashionable	shirts	or	writing	computer	code	–	so	how	will	they
survive?
If	AI	and	3-D
	printers	indeed	take	over	from	the	Bangladeshis	and
Bangalorians,	the	revenues	that	previously	flowed	to	South	Asia	will	now	fill	the
coffers	of	a	few	tech-giants	in	California.	Instead	of	economic	growth	improving
conditions	all	over	the	world,	we	might	see	immense	new	wealth	created	in	hi-
tech	hubs	such	as	Silicon	Valley,	while	many	developing	countries	collapse.
Of	course,	some	emerging	economies
	–	including	India	and	Bangladesh	–
might	advance	fast	enough	to	join	the	winning	team.	Given	enough	time,	the
children	or	grandchildren	of	textile	workers	and	call-centre	operators	might	well
become	the	engineers	and	entrepreneurs	who	build	and	own	the	computers	and
3-D	printers.	But	the	time	to	make	such	a	transition	is	running	out.	In	the	past,
cheap	unskilled	labour	has	served	as	a	secure
	bridge	across	the	global	economic
divide,	and	even	if	a	country	advanced	slowly,	it	could	expect	to	reach	safety
eventually.	Taking	the	right	steps	was	more	important	than	making	speedy
progress.	Yet	now	the	bridge	is	shaking,	and	soon	it	might	collapse.	Those	who
have	already	crossed	it	–	graduating	from	cheap	labour	to	high-skill	industries	–
will	probably	be	OK.	But	those	lagging	behind	might
	
find	themselves	stuck	on
the	wrong	side	of	the	chasm,	without	any	means	of	crossing	over.	What	do	youdo	when	nobody	needs	your	cheap	unskilled	labourers,	and	you	don’t	have	the
resources	to	build	a	good	education	system	and	teach	them	new	skills?
27
What	then	will	be	the	fate	of	the	stragglers?	American	voters	might
conceivably	agree	that	taxes	paid	by	Amazon	and	Google	for	their	US	business
could	be	used	to	give	stipends	or	free	services	to	unemployed	miners	in
Pennsylvania	and	jobless	taxi-drivers	in	New	York.	However,	would	American
voters	also	agree	that	these	taxes	should	be	sent	to	support	unemployed	people	in
places	defined	by	President	Trump	as	‘shithole	countries’?
28
	If	you	believe	that,
you	might	just	as	well	believe	that	Santa	Claus	and	the	Easter	Bunny	will	solve
the	problem.
What	is	basic?
Universal	basic	support	is	meant	to	take	care	of	basic	human	needs,	but	there	is
no	accepted	definition	for	that.	From	a	purely	biological	perspective,	a	Sapiens
needs	just	1,500–2,500	calories	per	day	in	order	to	survive.	Anything	more	is	a
luxury.	Yet	over	and	above	this	biological	poverty	line,	every	culture	in	history
defined	additional	needs	as	‘basic’.	In	medieval	Europe,
	access	to	church
services	was	seen	as	even	more	important	than	food,	because	it	took	care	of	your
eternal	soul	rather	than	of	your	ephemeral	body.	In	today’s	Europe,	decent
education	and	healthcare	services	are	considered	basic	human	needs,	and	some
argue	that	even	access	to	the	Internet	is	now	essential	for	every	man,	woman	and
child.	If	in	2050	the	United	World	Government	agrees	to	tax	Google,	Amazon,
Baidu	and	Tencent	in	order	to	provide	basic	support	for	every	human	being	on
earth	–	in	Dhaka	as	well	as	in	Detroit	–	how	will	they	define	‘basic’?
For	example,	what	does	basic	education	include:	just	reading	and	writing,	or
also	composing	computer	code	and	playing	the	violin?	Just	six	years	of
elementary	school,	or	everything	up	to	a	
PhD?	And	what	about	healthcare?	If	by
2050	medical	advances
	make	it	possible	to	slow	down	ageing	processes	and
significantly	extend	human	lifespans,	will	the	new	treatments	be	available	to	all
10	billion	humans	on	the	planet,	or	just	to	a	few	billionaires?	If	biotechnology
enables	parents	to	upgrade	their	children,	would	this	be	considered	a	basic
human	need,	or	would	we	see	humankind	splitting	into	different	biological
castes,	with	rich	superhumans	enjoying
	abilities	that	far	surpass	those	of	poor
Homo	sapiens
?
Whichever	way	you	choose	to	define	‘basic	human	needs’,	once	you	provide
them	to	everyone	free	of	charge,	they	will	be	taken	for	granted,	and	then	fiercesocial	competitions	and	political	struggles	will	focus	on	non-basic	luxuries	–	be
they	fancy	self-driving	cars,	access	to	virtual-reality	parks,	or	enhanced
bioengineered	bodies.	Yet	if
	the	unemployed	masses	command	no	economic
assets,	it	is	hard	to	see	how	they	could	ever	hope	to	obtain	such	luxuries.
Consequently	the	gap	between	the	rich	(Tencent	managers	and	Google
shareholders)	and	the	poor	(those	dependent	on	universal	basic	income)	might
become	not	merely	bigger,	but	actually	unbridgeable.
Hence	even	if	some	universal	support	scheme	provides	poor	people	in	2050
with	much
	better	healthcare	and	education	than	today,	they	might	still	be
extremely	angry	about	global	inequality	and	the	lack	of	social	mobility.	People
will	feel	that	the	system	is	rigged	against	them,	that	the	government	serves	only
the	super-rich,	and	that	the	future	will	be	even	worse	for	them	and	their
children.
29
Homo	sapiens
	is	just	not	built	for	satisfaction.	Human	happiness	depends	less
on	objective
	conditions	and	more	on	our	own	expectations.	Expectations,
however,	tend	to	adapt	to	conditions,	including	to	the	condition	of	
other	people
.
When	things	improve,	expectations	balloon,	and	consequently	even	dramatic
improvements	in	conditions	might	leave	us	as	dissatisfied	as	before.	If	universal
basic	support	is	aimed	at	improving	the	objective	conditions	of	the	average
person	in	2050,	it	has
	a	fair	chance	of	
succeeding.	But	if	it	is	aimed	at	making
people	subjectively	more	satisfied	with	their	lot	and	preventing	social	discontent,
it	is	likely	to	fail.
To	really	achieve	its	goals,	universal	basic	support	will	have	to	be
supplemented	by	some	meaningful	pursuits,	ranging	from	sports	to	religion.
Perhaps	the	most	successful	experiment	so	far	in	how	to	live	a	contented	life	in	a
post-work
	world	has	been	conducted	in	Israel.	There,	about	50%	of	ultra-
Orthodox	Jewish	men	never	work.	They	dedicate	their	lives	to	studying	holy
scriptures	and	performing	religious	rituals.	They	and	their	families	don’t	starve
partly	because	the	wives	often	work,	and	partly	because	the	government
provides	them	with	generous	subsidies	and	free	services,	making	sure	that	they
don’t	lack	the	basic	necessities
	of	life.	That’s	universal	basic	support	
avant	la
lettre
.
30
Although	they	are	poor	and	unemployed,	in	survey	after	survey	these	ultra-
Orthodox	Jewish	men	report	higher	levels	of	life	satisfaction	than	any	other
section	of	Israeli	society.	This	is	due	to	the	strength	of	their	community	bonds,
as	well	as	to	the	deep	meaning	they	find	in	studying	scriptures	and	performing
rituals.	A	small	room	full
	of	Jewish	men	discussing	the	Talmud	might	well
generate	more	joy,	engagement	and	insight	than	a	huge	textile	sweatshop	full	of
hard-working	factory	hands.	In	global	surveys	of	life	satisfaction,	Israel	isusually	somewhere	near	the	top,	thanks	in	part	to	the	contribution	of	these
jobless	poor	people.
31
Secular	Israelis	often	complain	bitterly	that	the	ultra-Orthodox	don’t
contribute	enough	to
	society,	and	live	off	other	people’s	hard	work.	Secular
Israelis	also	tend	to	argue	that	the	ultra-Orthodox	way	of	life	is	unsustainable,
especially	as	ultra-Orthodox	families	have	seven	children	on	average.
32
	Sooner	or
later,	the	state	will	not	be	able	to	support	so	many	unemployed	people,	and	the
ultra-Orthodox	will	have	to	go	to	work.	Yet	it	might	be	just	the	reverse.	As
robots	and	AI	push
	humans	out	of	the	job	market,	the	ultra-Orthodox	Jews	may
come	to	be	seen	as	the	model	of	the	future	rather	than	as	a	fossil	from	the	past.
Not	that	everyone	will	become	Orthodox	Jews	and	go	to	the	yeshivas	
to	study
the	Talmud.	But	in	the	lives	of	all	people,	the	quest	for	meaning	and	for
community	might	eclipse	the	quest	for	a	job.
If	we	manage	to	combine	a	universal	economic	safety	net	with
	strong
communities	and	meaningful	pursuits,	losing	our	jobs	to	the	algorithms	might
actually	turn	out	to	be	a	blessing.	Losing	control	over	our	lives,	however,	is	a
much	scarier	scenario.	Notwithstanding	the	danger	of	mass	unemployment,	what
we	should	worry	about	even	more	is	the	shift	in	authority	from	humans	to
algorithms,	which	might	destroy	any	remaining	faith	in	the	liberal	story	and
open	the
	way	to	the	rise	of	digital	dictatorships.3
LIBERTY
Big	Data	is	watching	you
The	liberal	story	cherishes	human	liberty	as	its	number	one	value.	It	argues	that
all	authority	ultimately	stems	from	the	free	will	of	individual	humans,	as	it	is
expressed	in	their	feelings,	desires	and	choices.	In	politics,	liberalism	believes
that	the	voter	knows	best.	It	therefore	upholds	democratic	elections.	In
economics,	liberalism	maintains	that	the	customer
	is	always	right.	It	therefore
hails	free-market	principles.	In	personal	matters,	liberalism	encourages	people	to
listen	to	themselves,	be	true	to	themselves,	and	follow	their	hearts	–	as	long	as
they	do	not	infringe	on	the	liberties	of	others.	This	personal	freedom	is	enshrined
in	human	rights.
In	Western	political	discourse	the	term	‘liberal’	is	sometimes	used	today	in	a
much	narrower	partisan
	sense,	to	denote	those	who	support	specific	causes	like
gay	marriage,	gun	control	and	abortion.	Yet	most	so-called	conservatives	also
embrace	the	broad	liberal	world	view.	Especially	in	the	United	States,	both
Republicans	and	Democrats	should	occasionally	take	a	break	from	their	heated
quarrels	to	remind	themselves	that	they	all	agree	on	fundamentals	such	as	free
elections,	an	independent	judiciary,
	and	human	rights.
In	particular,	it	is	vital	to	remember	that	right-wing	heroes	such	as	Ronald
Reagan	and	Margaret	Thatcher	were	great	champions	not	only	of	economic
freedoms	but	also	of	individual	liberties.	In	a	famous	interview	in	1987,
Thatcher	said	that	‘There	is	no	such	thing	as	society.	There	is	[a]	living	tapestry
of	men	and	
women	…	and	the	quality	of	our	lives	will	depend	upon	how	much
each	of	us	is	prepared	to	take	responsibility	for	ourselves.’
1
Thatcher’s	heirs	in	the	Conservative	Party	fully	agree	with	the	Labour	Party
that	political	authority	comes	from	the	feelings,	choices	and	free	will	of
individual	voters.	Thus	when	Britain	needed	to	decide	whether	it	should	leave
the	EU,	Prime	Minister	David	Cameron	didn’t	ask	Queen	Elizabeth	II,	theArchbishop	of	Canterbury,	or	the
	Oxford	and	Cambridge	dons	to	resolve	the
issue.	He	didn’t	even	ask	the	Members	of	Parliament.	Rather,	he	held	a
referendum	in	which	each	and	every	Briton	was	asked:	‘What	do	you	
feel
	about
it?’
You	might	object	that	people	were	asked	‘What	do	you	think?’	rather	than
‘What	do	you	feel?’,	but	this	is	a	common	misperception.	Referendums	and
elections	are	always	about	human	
feelings
,	not	about	human
	rationality.	If
democracy	were	a	matter	of	rational	decision-making,	there	would	be	absolutely
no	reason	to	give	all	people	equal	voting	rights	–	or	perhaps	any	voting	rights.
There	is	ample	evidence	that	some	people	are	far	more	knowledgeable	and
rational	than	others,	certainly	when	it	comes	to	specific	economic	and	political
questions.
2
	In	the	wake	of	the	Brexit	vote,	eminent	biologist	Richard
	Dawkins
protested	that	the	vast	majority	of	the	British	public	–	including	himself	–	should
never	have	been	asked	to	vote	in	the	referendum,	because	they	lacked	the
necessary	background	in	economics	and	political	science.	‘You	might	as	well
call	a	nationwide	plebiscite	to	decide	whether	Einstein	got	his	algebra	right,	or
let	passengers	vote	on	which	runway	the	pilot	should	land.’
3
However,	for
	better	or	worse,	elections	and	referendums	are	not	about	what
we	think.	They	are	about	what	we	feel.	And	when	it	comes	to	feelings,	Einstein
and	Dawkins	are	no	better	than	anyone	else.	Democracy	assumes	that	human
feelings	reflect	a	mysterious	and	profound	‘free	will’,	that	this	‘free	will’	is	the
ultimate	source	of	authority,	and	that	while	some	people	are	more	intelligent
than	others,	all	humans
	are	equally	free.	Like	Einstein	and	Dawkins,	an	illiterate
maid	also	has	free	will,	hence	on	election	
day	her	feelings	–	represented	by	her
vote	–	count	just	as	much	as	anybody	else’s.
Feelings	guide	not	just	the	voters,	but	also	the	leaders.	In	the	2016	Brexit
referendum	the	Leave	campaign	was	headed	together	by	Boris	Johnson	and
Michael	Gove.	After	David	Cameron	resigned,	Gove	initially	supported
	Johnson
for	the	premiership,	but	at	the	very	last	minute	Gove	declared	Johnson	unfit	for
the	position	and	announced	his	own	intention	to	run	for	the	job.	Gove’s	action,
which	destroyed	Johnson’s	chances,	was	described	as	a	Machiavellian	political
assassination.
4
	But	Gove	defended	his	conduct	by	appealing	to	his	feelings,
explaining	that	‘In	every	step	in	my	political	life	I	have	asked	myself	one
question:	“What	is	the	right	thing	to	do?	What	does	your	heart	tell	you?”’
5
	That’s
why,	according	to	Gove,	he	has	fought	so	hard	for	Brexit,	and	that’s	why	he	felt
compelled	to	backstab	his	erstwhile	ally	Boris	Johnson	and	bid	for	the	alpha-dog
position	himself	–	because	his	heart	told	him	to	do	it.
This	reliance	on	the	heart	might	prove	to	be	the	Achilles	heel	of	liberal
democracy.	For	once
	somebody	(whether	in	Beijing	or	in	San	Francisco)	gainsthe	technological	ability	to	hack	and	manipulate	the	human	heart,	democratic
politics	will	mutate	into	an	emotional	puppet	show.
Listen	to	the	algorithm
The	liberal	belief	in	the	feelings	and	free	choices	of	individuals	is	neither	natural
nor	very	ancient.	For	thousands	of	years	people	believed	that	authority	came
from	divine	laws	rather
	than	from	the	human	heart,	and	that	we	should	therefore
sanctify	the	word	of	God	rather	than	human	liberty.	Only	in	the	last	few
centuries	did	the	source	of	authority	shift	from	celestial	deities	to	flesh-and-
blood	humans.
Soon	authority	might	shift	again	–	from	humans	to	algorithms.	Just	as	divine
authority	was	legitimised	by	religious	
mythologies,	and	human	authority	was
justified	by	the	liberal
	story,	so	the	coming	technological	revolution	might
establish	the	authority	of	Big	Data	algorithms,	while	undermining	the	very	idea
of	individual	freedom.
As	we	mentioned	in	the	previous	chapter,	scientific	insights	into	the	way	our
brains	and	bodies	work	suggest	that	our	feelings	are	not	some	uniquely	human
spiritual	quality,	and	they	do	not	reflect	any	kind	of	‘free	will’.	Rather,	feelings
are	biochemical	mechanisms	that	all	mammals	and	birds	use	in	order	to	quickly
calculate	probabilities	of	survival	and	reproduction.	Feelings	aren’t	based	on
intuition,	inspiration	or	freedom	–	they	are	based	on	calculation.
When	a	monkey,	mouse	or	human	sees	a	snake,	fear	arises	because	millions	of
neurons	in	the	brain	swiftly	calculate	the	relevant	data	and	conclude	that	the
probability	of	death
	is	high.	Feelings	of	sexual	attraction	arise	when	other
biochemical	algorithms	calculate	that	a	nearby	individual	offers	a	high
probability	of	successful	mating,	social	bonding,	or	some	other	coveted	goal.
Moral	feelings	such	as	outrage,	guilt	or	forgiveness	derive	from	neural
mechanisms	that	evolved	to	enable	group	cooperation.	All	these	biochemical
algorithms	were	honed	through	millions	of
	years	of	evolution.	If	the	feelings	of
some	ancient	ancestor	made	a	mistake,	the	genes	shaping	these	feelings	did	not
pass	on	to	the	next	generation.	Feelings	are	thus	not	the	opposite	of	rationality	–
they	embody	evolutionary	rationality.
We	usually	fail	to	realise	that	feelings	are	in	fact	calculations,	because	the
rapid	process	of	calculation	occurs	far	below	our	threshold	of	awareness.	We
don’t	feel	the	millions	of	neurons	in	the	brain	computing	probabilities	of	survival
and	reproduction,	so	we	erroneously	believe	that	our	fear	of	snakes,	our	choiceof	sexual	mates,	or	our	opinions	about	the	European	Union	are	the	result	of	some
mysterious	‘free	will’.
Nevertheless,	though	liberalism	is	wrong	to	think	that	our	feelings	reflect	a
free	will,	up	until	today	relying	on	feelings	still
	made	good	practical	sense.	For
although	there	was	nothing	magical	or	
free	about	our	feelings,	they	were	the	best
method	in	the	universe	for	deciding	what	to	study,	who	to	marry,	and	which
party	to	vote	for.	And	no	outside	system	could	hope	to	understand	my	feelings
better	than	me.	Even	if	the	Spanish	Inquisition	or	the	Soviet	KGB	spied	on	me
every	minute	of	every	day,	they	lacked	the	biological
	knowledge	and	the
computing	power	necessary	to	hack	the	biochemical	processes	shaping	my
desires	and	choices.	For	all	practical	purposes,	it	was	reasonable	to	argue	that	I
have	free	will,	because	my	will	was	shaped	mainly	by	the	interplay	of	inner
forces,	which	nobody	outside	could	see.	I	could	enjoy	the	illusion	that	I	control
my	secret	inner	arena,	while	outsiders	could	never	really	understand
	what	is
happening	inside	me	and	how	I	make	decisions.
Accordingly,	liberalism	was	correct	in	counselling	people	to	follow	their	heart
rather	than	the	dictates	of	some	priest	or	party	apparatchik.	However,	soon
computer	algorithms	could	give	you	better	counsel	than	human	feelings.	As	the
Spanish	Inquisition	and	the	KGB	give	way	to	Google	and	Baidu,	‘free	will’	will
likely	be	exposed	as	a	myth,
	and	liberalism	might	lose	its	practical	advantages.
For	we	are	now	at	the	confluence	of	two	immense	revolutions.	On	the	one
hand	biologists	are	deciphering	the	mysteries	of	the	human	body,	and	in
particular,	of	the	brain	and	of	human	feelings.	At	the	same	time	computer
scientists	are	giving	us	unprecedented	data-processing	power.	When	the	biotech
revolution	merges	with	the	infotech	revolution,
	it	will	produce	Big	Data
algorithms	that	can	monitor	and	understand	my	feelings	much	better	than	I	can,
and	then	authority	will	probably	shift	from	humans	to	computers.	My	illusion	of
free	will	is	likely	to	disintegrate	as	I	daily	encounter	institutions,	corporations
and	government	agencies	that	understand	and	manipulate	what	was	hitherto	my
inaccessible	inner	realm.
This	is	already	happening
	in	the	field	of	medicine.	The	most	important
medical	decisions	in	our	life	rely	not	on	our	feelings	of	illness	or	wellness,	or
even	on	the	informed	predictions	of	our	doctor	–	but	on	the	calculations	of
computers	which	understand	our	
bodies	much	better	than	we	do.	Within	a	few
decades,	Big	Data	algorithms	informed	by	a	constant	stream	of	biometric	data
could	monitor	our	health	24/7.	They	could
	detect	the	very	beginning	of
influenza,	cancer	or	Alzheimer’s	disease,	long	before	we	feel	anything	is	wrong
with	us.	They	could	then	recommend	appropriate	treatments,	diets	and	daily
regimens,	custom-built	for	our	unique	physique,	DNA	and	personality.People	will	enjoy	the	best	healthcare	in	history,	but	for	precisely	this	reason
they	will	probably	be	sick	all	the	time.	There	is	always	something
	wrong
somewhere	in	the	body.	There	is	always	something	that	can	be	improved.	In	the
past,	you	felt	perfectly	healthy	as	long	as	you	didn’t	sense	pain	or	you	didn’t
suffer	from	an	apparent	disability	such	as	limping.	But	by	2050,	thanks	to
biometric	sensors	and	Big	Data	algorithms,	diseases	may	be	diagnosed	and
treated	long	before	they	lead	to	pain	or	disability.	As	a	result,	you	will	always
find
	yourself	suffering	from	some	‘medical	condition’	and	following	this	or	that
algorithmic	recommendation.	If	you	refuse,	perhaps	your	medical	insurance
would	become	invalid,	or	your	boss	would	fire	you	–	why	should	they	pay	the
price	of	your	obstinacy?
It	is	one	thing	to	continue	smoking	despite	general	statistics	that	connect
smoking	with	lung	cancer.	It	is	a	very	different	thing	to	continue	smoking
despite	a	concrete	warning	from	a	biometric	sensor	that	has	just	detected
seventeen	cancerous	cells	in	your	upper	left	lung.	And	if	you	are	willing	to	defy
the	sensor,	what	will	you	do	when	the	sensor	forwards	the	warning	to	your
insurance	agency,	your	manager,	and	your	mother?
Who	will	have	the	time	and	energy	to	deal	with	all	these	illnesses?	In	all
likelihood,	we	could	just	instruct	our	health
	algorithm	to	deal	with	most	of	these
problems	as	it	sees	fit.	At	most,	it	will	send	periodic	updates	to	our	smartphones,
telling	us	that	‘seventeen	cancerous	cells	were	detected	and	destroyed’.
Hypochondriacs	might	dutifully	read	these	updates,	but	most	of	us	will	ignore
them	just	as	we	ignore	those	annoying	anti-virus	notices	on	our	computers.
The	drama	of	decision-making
What	is	already	beginning
	to	happen	in	medicine	is	likely	to	occur	in	more	and
more	fields.	The	key	invention	is	the	biometric	sensor,	which	people	can	wear
on	or	inside	their	bodies,	and	which	converts	biological	processes	into	electronic
information	that	computers	can	store	and	analyse.	Given	enough	biometric	data
and	enough	computing	power,	external	data-processing	systems	can	hack	all
your	desires,	decisions	and
	opinions.	They	can	know	exactly	who	you	are.
Most	people	don’t	know	themselves	very	well.	When	I	was	twenty-one,	I
finally	realised	that	I	was	gay,	after	several	years	of	living	in	denial.	That’s
hardly	exceptional.	Many	gay	men	spend	their	entire	teenage	years	unsure	about
their	sexuality.	Now	imagine	the	situation	in	2050,	when	an	algorithm	can	tell
any	teenager	exactly	where	he	is	on	the	gay/straight
	spectrum	(and	even	howmalleable	that	position	is).	Perhaps	the	algorithm	shows	you	pictures	or	videos
of	attractive	men	and	women,	tracks	your	eye	movements,	blood	pressure	and
brain	activity,	and	within	five	minutes	ejects	a	number	on	the	Kinsey	scale.
6
	It
could	have	saved	me	years	of	frustration.	Perhaps	you	personally	wouldn’t	want
to	take	such	a	test,	but	then	maybe	you	find	yourself	with
	a	group	of	friends	at
Michelle’s	boring	birthday	party,	and	somebody	suggests	you	all	take	turns
checking	yourself	on	this	cool	new	algorithm	(with	everybody	standing	around
to	watch	the	results	–	and	comment	on	them).	Would	you	just	walk	away?
Even	if	you	do,	and	even	if	you	keep	hiding	from	yourself	and	your
classmates,	you	won’t	be	able	to	hide	from	Amazon,	Alibaba	or	the	secret
police.	As
	you	surf	the	Web,	watch	YouTube	or	read	your	social	media	feed,	the
algorithms	will	discreetly	monitor	you,	analyse	you,	and	tell	Coca-Cola	that	if	it
wants	to	sell	you	some	fizzy	drink,	it	had	better	use	the	advertisement	with	the
shirtless	guy	rather	than	the	shirtless	girl.	You	won’t	even	know.	But	they	will
know,	and	such	information	will	be	worth	billions.
Then	again,	maybe	it	will	all	be
	out	in	the	open,	and	people	will	gladly	share
their	information	in	order	to	get	better	recommendations	–	and	eventually	in
order	to	get	the	algorithm	to	make	decisions	for	them.	It	starts	with	simple
things,	like	deciding	which	movie	to	watch.	As	you	sit	down	with	a	group	of
friends	to	spend	a	cozy	evening	in	front	of	the	TV,	you	first	have	to	choose	what
to	see.	Fifty	years	ago	you	had	no	choice,
	but	today	–	with	the	rise	of	view-on-
demand	services	–	there	are	thousands	of	titles	available.	Reaching	an	agreement
can	be	quite	difficult,	because	while	you	personally	like	science-fiction	thrillers,
Jack	prefers	romantic	comedies,	and	Jill	votes	for	artsy	French	films.	You	may
well	end	up	compromising	on	some	mediocre	B-movie	that	disappoints	all	of
you.
An	algorithm	might	help.	You	can	tell
	it	which	previous	movies	each	of	you
really	liked,	and	based	on	its	massive	statistical	database,	the	algorithm	can	then
find	the	perfect	match	for	the	group.	Unfortunately,	such	a	crude	algorithm	is
easily	misled,	particularly	because	self-reporting	is	a	notoriously	unreliable
gauge	for	people’s	true	preferences.	It	often	happens	that	we	hear	lots	of	people
praise	some	movie	as	a	masterpiece,
	feel	compelled	to	watch	it,	and	even	though
we	fall	asleep	midway	through,	we	don’t	want	to	look	like	philistines,	so	we	tell
everyone	it	was	an	amazing	experience.
7
Such	problems,	however,	can	be	solved	if	we	just	allow	the	algorithm	to
collect	real-time	data	on	us	as	we	actually	watch	movies,	instead	of	relying	on
our	own	dubious	self-reports.	For	starters,	the	algorithm	can	monitor	which
movies
	we	completed,	and	which	we	stopped	watching	halfway	through.	Even	if
we	tell	the	whole	world	that	
Gone	With	the	Wind
	is	the	best	movie	ever	made,the	algorithm	will	know	we	never	made	it	past	the	first	half-hour,	and	we	never
really	saw	Atlanta	burning.
Yet	the	algorithm	can	go	much	deeper	than	that.	Engineers	are	currently
developing	software	that	can	detect	human	emotions	based	on	the	movements
	of
our	eyes	and	facial	muscles.
8
	Add	a	good	camera	to	the	television,	and	such
software	will	know	which	
scenes	made	us	laugh,	which	scenes	made	us	sad,	and
which	scenes	bored	us.	Next,	connect	the	algorithm	to	biometric	sensors,	and	the
algorithm	will	know	how	each	frame	has	influenced	our	heart	rate,	our	blood
pressure,	and	our	brain	activity.	As	we	watch,	say,	Tarantino’s	
Pulp	Fiction
,	the
algorithm
	may	note	that	the	rape	scene	caused	us	an	almost	imperceptible	tinge
of	sexual	arousal,	that	when	Vincent	accidentally	shot	Marvin	in	the	face	it	made
us	laugh	guiltily,	and	that	we	didn’t	get	the	joke	about	the	Big	Kahuna	Burger	–
but	we	laughed	anyway,	so	as	not	to	look	stupid.	When	you	force	yourself	to
laugh,	you	use	different	brain	circuits	and	muscles	than	when	you	laugh	because
something
	is	really	funny.	Humans	cannot	usually	detect	the	difference.	But	a
biometric	sensor	could.
9
The	word	television	comes	from	Greek	‘
tele
’,	which	means	‘far’,	and	Latin
‘
visio
’,	sight.	It	was	originally	conceived	as	a	device	that	allows	us	to	see	from
afar.	But	soon,	it	might	allow	us	to	
be	seen
	from	afar.	As	George	Orwell
envisioned	in	
Nineteen	Eighty-Four
,	the	television	will	watch	us	while	we
	are
watching	it.	After	we’ve	finished	watching	Tarantino’s	entire	filmography,	we
may	have	forgotten	most	of	it.	But	Netflix,	or	Amazon,	or	whoever	owns	the	TV
algorithm,	will	know	our	personality	type,	and	how	to	press	our	emotional
buttons.	Such	data	could	enable	Netflix	and	Amazon	to	choose	movies	for	us
with	uncanny	precision,	but	it	could	also	enable	them	to	make	for	us	the	most
important	decisions
	in	life	–	such	as	what	to	study,	where	to	work,	and	who	to
marry.
Of	course	Amazon	won’t	be	correct	all	the	time.	That’s	impossible.
Algorithms	will	repeatedly	make	mistakes	due	to	insufficient	data,	faulty
programming,	muddled	goal	definitions	and	the	chaotic	nature	of	life.
10
	But
Amazon	won’t	have	to	be	perfect.	It	will	just	need	to	be	better	on	average	than
us	humans.	And	that	is	not	so	difficult,
	because	most	people	don’t	know
themselves	very	well,	and	most	people	often	make	terrible	mistakes	in	the	most
important	decisions	of	their	lives.	Even	more	than	algorithms,	humans	suffer
from	insufficient	data,	from	faulty	programming	
(genetic	and	cultural),	from
muddled	definitions,	and	from	the	chaos	of	life.
You	may	well	list	the	many	problems	that	beset	algorithms,	and	conclude	that
people
	will	never	trust	them.	But	this	is	a	bit	like	cataloguing	all	the	drawbacks
of	democracy	and	concluding	that	no	sane	person	would	ever	choose	to	supportsuch	a	system.	Winston	Churchill	famously	said	that	democracy	is	the	worst
political	system	in	the	world,	except	for	all	the	others.	Rightly	or	wrongly,
people	might	reach	the	same	conclusions	about	Big	Data	algorithms:	they	have
lots	of	hitches,
	but	we	have	no	better	alternative.
As	scientists	gain	a	deeper	understanding	of	the	way	humans	make	decisions,
the	temptation	to	rely	on	algorithms	is	likely	to	increase.	Hacking	human
decision-making	will	not	only	make	Big	Data	algorithms	more	reliable,	it	will
simultaneously	make	human	feelings	
less
	reliable.	As	governments	and
corporations	succeed	in	hacking	the	human	operating	system,	we
	will	be
exposed	to	a	barrage	of	precision-guided	manipulation,	advertisement	and
propaganda.	It	might	become	so	easy	to	manipulate	our	opinions	and	emotions
that	we	will	be	forced	to	rely	on	algorithms	in	the	same	way	that	a	pilot	suffering
an	attack	of	vertigo	must	ignore	what	his	own	senses	are	telling	him	and	put	all
his	trust	in	the	machinery.
In	some	countries	and	in	some	situations,	people
	might	not	be	given	any
choice,	and	they	will	be	forced	to	obey	the	decisions	of	Big	Data	algorithms.	Yet
even	in	allegedly	free	societies,	algorithms	might	gain	authority	because	we	will
learn	from	experience	to	trust	them	on	more	and	more	issues,	and	will	gradually
lose	our	ability	to	make	decisions	for	ourselves.	Just	think	of	the	way	that	within
a	mere	two	decades,	billions	of	people	have	come
	to	entrust	the	Google	search
algorithm	with	one	of	the	most	important	tasks	of	all:	searching	for	relevant	and
trustworthy	information.	We	no	longer	search	for	information.	Instead,	we
google.	And	as	we	increasingly	rely	on	Google	for	answers,	so	our	ability	to
search	for	information	by	ourselves	diminishes.	
Already	today,	‘truth’	is	defined
by	the	top	results	of	the	Google	search.
11
This	has
	also	been	happening	with	physical	abilities,	such	as	navigating	space.
People	ask	Google	to	guide	them	around.	When	they	reach	an	intersection,	their
gut	feeling	might	tell	them	‘turn	left’,	but	Google	Maps	says	‘turn	right’.	At	first
they	listen	to	their	gut	feeling,	turn	left,	get	stuck	in	a	traffic	jam,	and	miss	an
important	meeting.	Next	time	they	listen	to	Google,	turn	right,	and	make	it	on
time.	They	learn	from	experience	to	trust	Google.	Within	a	year	or	two,	they
blindly	rely	on	whatever	Google	Maps	tells	them,	and	if	the	smartphone	fails,
they	are	completely	clueless.	In	March	2012	three	Japanese	tourists	in	Australia
decided	to	take	a	day	trip	to	a	small	offshore	island,	and	drove	their	car	straight
into	the	Pacific	Ocean.	The	driver,	twenty-one-year-old	Yuzu	Nuda,	later	said
that
	she	just	followed	the	instructions	of	the	GPS	and	‘it	told	us	we	could	drive
down	there.	It	kept	saying	it	would	navigate	us	to	a	road.	We	got	stuck.’
12
	In
several	similar	incidents	people	drove	into	a	lake,	or	fell	off	a	demolished
bridge,	by	apparently	following	GPS	instructions.
13
	The	ability	to	navigate	is	likea	muscle	–	use	it	or	lose	it.
14
	The	same	is	true	for	the	ability	to	choose	spouses
	or
professions.
Every	year	millions	of	youngsters	need	to	decide	what	to	study	at	university.
This	is	a	very	important	and	very	difficult	decision.	You	are	under	pressure	from
your	parents,	your	friends	and	your	teachers,	who	have	different	interests	and
opinions.	You	also	have	your	own	fears	and	fantasies	to	deal	with.	Your
judgement	is	clouded	and	manipulated	by	Hollywood	blockbusters,	trashy
novels,	and	sophisticated	advertising	campaigns.	It	is	particularly	difficult	to
make	a	wise	decision	because	you	do	not	really	know	what	it	takes	to	succeed	in
different	professions,	and	you	don’t	necessarily	have	a	realistic	image	of	your
own	strengths	and	weaknesses.	What	does	it	take	to	succeed	as	a	lawyer?	How
do	I	perform	under	pressure?	Am	I	a	good	team-worker?
One	student	might	start
	law	school	because	she	has	an	inaccurate	image	of	her
own	skills,	and	an	even	more	distorted	view	
of	what	being	a	lawyer	actually
involves	(you	don’t	get	to	give	dramatic	speeches	and	shout	‘Objection,	Your
Honour!’	all	day).	Meanwhile	her	friend	decides	to	fulfil	a	childhood	dream	and
study	professional	ballet	dancing,	even	though	she	doesn’t	have	the	necessary
bone	structure	or	discipline.	Years
	later,	both	deeply	regret	their	choices.	In	the
future	we	could	rely	on	Google	to	make	such	decisions	for	us.	Google	could	tell
me	that	I	would	be	wasting	my	time	in	law	school	or	in	ballet	school	–	but	that	I
might	make	an	excellent	(and	very	happy)	psychologist	or	plumber.
15
Once	AI	makes	better	decisions	than	us	about	careers	and	perhaps	even
relationships,	our	concept	of	humanity	and	of	life
	will	have	to	change.	Humans
are	used	to	thinking	about	life	as	a	drama	of	decision-making.	Liberal
democracy	and	free-market	capitalism	see	the	individual	as	an	autonomous	agent
constantly	making	choices	about	the	world.	Works	of	art	–	be	they	Shakespeare
plays,	Jane	Austen	novels,	or	tacky	Hollywood	comedies	–	usually	revolve
around	the	hero	having	to	make	some	particularly	crucial	decision.
	To	be	or	not
to	be?	To	listen	to	my	wife	and	kill	King	Duncan,	or	listen	to	my	conscience	and
spare	him?	To	marry	Mr	Collins	or	Mr	Darcy?	Christian	and	Muslim	theology
similarly	focus	on	the	drama	of	decision-making,	arguing	that	everlasting
salvation	or	damnation	depends	on	making	the	right	choice.
What	will	happen	to	this	view	of	life	as	we	increasingly	rely	on	AI	to	make
decisions	for	us?
	At	present	we	trust	Netflix	to	recommend	movies,	and	Google
Maps	to	choose	whether	to	turn	right	or	left.	But	once	we	begin	to	count	on	AI	to
decide	what	to	study,	where	to	work,	and	who	to	marry,	human	life	will	cease	to
be	a	drama	of	decision-making.	Democratic	elections	and	free	markets	will	make
little	sense.	So	would	most	religions	and	works	of	art.	Imagine	Anna	Karenina
taking	out	her	smartphone
	and	asking	the	Facebook	algorithm	whether	sheshould	stay	married	to	Karenin	or	elope	with	the	dashing	Count	Vronsky.	Or
imagine	your	favourite	Shakespeare	play	with	all	the	crucial	decisions	taken	by
the	Google	algorithm.	Hamlet	and	Macbeth	will	have	much	
more	comfortable
lives,	but	what	kind	of	life	will	it	be	exactly?	Do	we	have	models	for	making
sense	of	such	a	life?
As	authority	shifts	from
	humans	to	algorithms,	we	may	no	longer	see	the
world	as	the	playground	of	autonomous	individuals	struggling	to	make	the	right
choices.	Instead,	we	might	perceive	the	entire	universe	as	a	flow	of	data,	see
organisms	as	little	more	than	biochemical	algorithms,	and	believe	that
humanity’s	cosmic	vocation	is	to	create	an	all-encompassing	data-processing
system	–	and	then	merge	into	it.	Already	today
	we	are	becoming	tiny	chips
inside	a	giant	data-processing	system	that	nobody	really	understands.	Every	day
I	absorb	countless	data	bits	through	emails,	tweets	and	articles;	process	the	data;
and	transmit	back	new	bits	through	more	emails,	tweets	and	articles.	I	don’t
really	know	where	I	fit	into	the	great	scheme	of	things,	and	how	my	bits	of	data
connect	with	the	bits	produced	by	billions	of	other
	humans	and	computers.	I
don’t	have	time	to	find	out,	because	I	am	too	busy	answering	all	these	emails.
The	philosophical	car
People	might	object	that	algorithms	could	never	make	important	decisions	for
us,	because	important	decisions	usually	involve	an	ethical	dimension,	and
algorithms	don’t	understand	ethics.	Yet	there	is	no	reason	to	assume	that
algorithms	won’t	be	able	to	outperform	the	average
	human	even	in	ethics.
Already	today,	as	devices	like	smartphones	and	autonomous	vehicles	undertake
decisions	that	used	to	be	a	human	monopoly,	they	start	to	grapple	with	the	same
kind	of	ethical	problems	that	have	bedevilled	humans	for	millennia.
For	example,	suppose	two	kids	chasing	a	ball	jump	right	in	front	of	a	self-
driving	car.	Based	on	its	lightning	calculations,	the	algorithm	driving	the
	car
concludes	that	the	only	way	to	avoid	hitting	the	two	kids	is	to	swerve	into	the
opposite	lane,	and	risk	colliding	with	an	oncoming	truck.	The	algorithm
calculates	that	
in	such	a	case	there	is	a	70	per	cent	chance	that	the	owner	of	the
car	–	who	is	fast	asleep	in	the	back	seat	–	would	be	killed.	What	should	the
algorithm	do?
16
Philosophers	have	been	arguing	about	such	‘trolley	problems’	for
	millennia
(they	are	called	‘trolley	problems’	because	the	textbook	examples	in	modern
philosophical	debates	refer	to	a	runaway	trolley	car	racing	down	a	railway	track,rather	than	to	a	self-driving	car).
17
	Up	till	now,	these	arguments	have	had
embarrassingly	little	impact	on	actual	behaviour,	because	in	times	of	crisis
humans	all	too	often	forget	about	their	philosophical	views	and	follow	their
emotions	and	gut	instincts	instead.
One	of	the	nastiest	experiments	in	the	history	of	the	social	sciences	was
conducted	in	December	1970	on	a	group	of	students	at	the	Princeton	Theological
Seminary,	who	were	training	to	become	ministers	in	the	Presbyterian	Church.
Each	student	was	asked	to	hurry	to	a	distant	lecture	hall,	and	there	give	a	talk	on
the	Good	Samaritan	parable,	which	tells	how	a
	Jew	travelling	from	Jerusalem	to
Jericho	was	robbed	and	beaten	by	criminals,	who	then	left	him	to	die	by	the	side
of	the	road.	After	some	time	a	priest	and	a	Levite	passed	nearby,	but	both
ignored	the	man.	In	contrast,	a	Samaritan	–	a	member	of	a	sect	much	despised	by
the	Jews	–	stopped	when	he	saw	the	victim,	took	care	of	him,	and	saved	his	life.
The	moral	of	the	parable	is	that	people’s	merit	should
	be	judged	by	their	actual
behaviour,	rather	than	by	their	religious	affiliaton.
The	eager	young	seminarians	rushed	to	the	lecture	hall,	contemplating	on	the
way	how	best	to	explain	the	moral	of	the	Good	Samaritan	parable.	But	the
experimenters	planted	in	their	path	a	shabbily	dressed	person,	who	was	sitting
slumped	in	a	doorway	with	his	head	down	and	his	eyes	closed.	As	each
unsuspecting	seminarian
	was	hurrying	past,	the	‘victim’	coughed	and	groaned
pitifully.	Most	seminarians	did	not	even	stop	to	enquire	what	was	wrong	with	the
man,	let	alone	offer	any	help.	The	emotional	stress	created	by	the	need	to	hurry
to	the	lecture	hall	trumped	their	moral	obligation	to	help	strangers	in	distress.
18
Human	emotions	trump	philosophical	theories	in	countless	other	situations.
This	makes	the	ethical
	and	philosophical	history	of	the	world	a	rather	depressing
tale	of	wonderful	ideals	and	less	than	ideal	behaviour.	How	many	Christians
actually	turn	the	other	cheek,	how	many	Buddhists	actually	rise	above	egoistic
obsessions,	and	how	many	Jews	actually	love	their	neighbours	as	themselves?
That’s	just	the	way	natural	selection	has	shaped	
Homo	sapiens
.	Like	all
mammals,	
Homo	sapiens
	uses	emotions
	to	quickly	make	life	and	death
decisions.	We	have	inherited	our	anger,	our	fear	and	our	lust	from	millions	of
ancestors,	all	of	whom	passed	the	most	rigorous	quality	control	tests	of	natural
selection.
Unfortunately,	what	was	good	for	survival	and	reproduction	in	the	African
savannah	a	million	years	ago	does	not	necessarily	make	for	responsible
behaviour	on	twenty-first-century	motorways.	Distracted,
	angry	and	anxious
human	drivers	kill	more	than	a	million	people	in	traffic	accidents	every	year.	We
can	send	all	our	philosophers,	prophets	and	priests	to	preach	ethics	to	these
drivers	–	but	on	the	road,	mammalian	emotions	and	savannah	instincts	will	stilltake	over.	Consequently,	seminarians	in	a	rush	will	ignore	people	in	distress,	and
drivers	in	a	crisis	will	run	over	hapless	pedestrians.
This	disjunction	between	the	seminary	and	the	road	is	one	of	the	biggest
practical	problems	in	ethics.	Immanuel	Kant,	John	Stuart	Mill	and	John	Rawls
can	sit	in	some	cosy	university	hall	and	discuss	theoretical	problems	in	ethics	for
days	–	but	would	their	conclusions	actually	be	implemented	by	stressed-out
drivers	caught	in	a	split-second	emergency?	Perhaps	Michael	Schumacher	–	the
Formula	One	champion
	who	is	sometimes	hailed	as	the	best	driver	in	history	–
had	the	ability	to	think	about	philosophy	while	racing	a	car;	but	most	of	us	aren’t
Schumacher.
Computer	algorithms,	however,	have	not	been	shaped	by	natural	selection,
and	they	have	neither	emotions	nor	gut	instincts.	Hence	in	moments	of	crisis
they	could	follow	ethical	guidelines	much	better	than	humans	–	provided	we	find
a	way	to	code
	ethics	in	precise	numbers	and	statistics.	If	we	teach	Kant,	Mill	and
Rawls	to	write	code,	they	can	carefully	program	the	self-driving	car	in	
their	cosy
laboratory,	and	be	certain	that	the	car	will	follow	their	commandments	on	the
highway.	In	effect,	every	car	will	be	driven	by	Michael	Schumacher	and
Immanuel	Kant	rolled	into	one.
Thus	if	you	program	a	self-driving	car	to	stop	and	help	strangers
	in	distress,	it
will	do	so	come	hell	or	high	water	(unless,	of	course,	you	insert	an	exception
clause	for	infernal	or	high-water	scenarios).	Similarly,	if	your	self-driving	car	is
programmed	to	swerve	to	the	opposite	lane	in	order	to	save	the	two	kids	in	its
path,	you	can	bet	your	life	this	is	exactly	what	it	will	do.	Which	means	that	when
designing	their	self-driving	car,	Toyota	or	Tesla	will
	be	transforming	a
theoretical	problem	in	the	philosophy	of	ethics	into	a	practical	problem	of
engineering.
Granted,	the	philosophical	algorithms	will	never	be	perfect.	Mistakes	will	still
happen,	resulting	in	injuries,	deaths	and	extremely	complicated	lawsuits.	(For
the	first	time	in	history,	you	might	be	able	to	sue	a	philosopher	for	the
unfortunate	results	of	his	or	her	theories,	because	for
	the	first	time	in	history	you
could	prove	a	direct	causal	link	between	philosophical	ideas	and	real-life
events.)	However,	in	order	to	take	over	from	human	drivers,	the	algorithms
won’t	have	to	be	perfect.	They	will	just	have	to	be	better	than	the	humans.	Given
that	human	drivers	kill	more	than	a	million	people	each	year,	that	isn’t	such	a	tall
order.	When	all	is	said	and	done,	would	you	rather
	the	car	next	to	you	was
driven	by	a	drunk	teenager,	or	by	the	Schumacher–Kant	team?
19
The	same	logic	is	true	not	just	of	driving,	but	of	many	other	situations.	Take
for	example	job	applications.	In	the	twenty-first	century,	the	decision	whether	to
hire	somebody	for	a	job	will	increasingly	be	made	by	algorithms.	We	cannot	relyon	the	machine	to	set	the	relevant	ethical	standards	–	humans	will
	still	need	to	do
that.	But	once	we	decide	on	an	ethical	standard	in	the	job	market	–	that	it	is
wrong	to	discriminate	against	black	people	or	against	women,	for	example	–	we
can	rely	on	machines	to	implement	and	maintain	this	standard	better	than
humans.
20
A	human	manager	may	know	and	even	agree	that	it	is	unethical	to
discriminate	against	black	people	and	women,	but	then,	
when	a	black	woman
applies	for	a	job,	the	manager	subconsciously	discriminates	against	her,	and
decides	not	to	hire	her.	If	we	allow	a	computer	to	evaluate	job	applications,	and
program	the	computer	to	completely	ignore	race	and	gender,	we	can	be	certain
that	the	computer	will	indeed	ignore	these	factors,	because	computers	don’t	have
a	subconscious.	Of	course,	it	won’t	be	easy	to	write	code	for	evaluating	job
applications,
	and	there	is	always	a	danger	that	the	engineers	will	somehow
program	their	own	subconscious	biases	into	the	software.
21
	Yet	once	we	discover
such	mistakes,	it	would	probably	be	far	easier	to	debug	the	software	than	to	rid
humans	of	their	racist	and	misogynist	biases.
We	saw	that	the	rise	of	artificial	intelligence	might	push	most	humans	out	of
the	job	market	–	including	drivers	and	traffic	police
	(when	rowdy	humans	are
replaced	by	obedient	algorithms,	traffic	police	will	be	redundant).	However,
there	might	be	some	new	openings	for	philosophers,	because	their	skills	–
hitherto	devoid	of	much	market	value	–	will	suddenly	be	in	very	high	demand.
So	if	you	want	to	study	something	that	will	guarantee	a	good	job	in	the	future,
maybe	philosophy	is	not	such	a	bad	gamble.
Of	course,	philosophers
	seldom	agree	on	the	right	course	of	action.	Few
‘trolley	problems’	have	been	solved	to	the	satisfaction	of	all	philosophers,	and
consequentialist	thinkers	such	as	John	Stuart	Mill	(who	judge	actions	by
consequences)	hold	quite	different	opinions	to	deontologists	such	as	Immanuel
Kant	(who	judge	actions	by	absolute	rules).	Would	Tesla	have	to	actually	take	a
stance	on	such	knotty	matters	in	order
	to	produce	a	car?
Well,	maybe	Tesla	will	just	leave	it	to	the	market.	Tesla	will	produce	two
models	of	the	self-driving	car:	the	Tesla	Altruist	and	the	Tesla	Egoist.	In	an
emergency,	the	Altruist	sacrifices	its	owner	to	the	greater	good,	whereas	the
Egoist	does	everything	in	its	power	to	save	its	owner,	even	if	it	means	killing	the
two	kids.	Customers	will	then	be	able	to	buy	the	car	that	best
	fits	their	favourite
philosophical	view.	If	more	people	buy	the	Tesla	Egoist,	you	won’t	be	able	to
blame	Tesla	for	that.	After	all,	the	customer	is	always	right.
This	is	not	a	joke.	In	a	pioneering	2015	study	people	were	presented	with	a
hypothetical	scenario	of	a	self-driving	car	about	to	run	over	several	pedestrians.
Most	said	that	in	such	a	case	the	car	should	save	the	pedestrians	even	at
	the	priceof	killing	its	owner.	When	they	were	then	asked	whether	they	personally	would
buy	a	car	programmed	to	sacrifice	its	owner	for	the	greater	good,	most	said	no.
For	themselves,	they	would	prefer	the	Tesla	Egoist.
22
Imagine	the	situation:	you	have	bought	a	new	car,	but	before	you	can	start
using	it,	you	must	open	the	settings	menu	and	tick	one	of	several	boxes.	In	case
of	an	accident,	do
	you	want	the	car	to	sacrifice	your	life	–	or	to	kill	the	family	in
the	other	vehicle?	Is	this	a	choice	you	even	want	to	make?	Just	think	of	the
arguments	you	are	going	to	have	with	your	husband	about	which	box	to	tick.
So	maybe	the	state	should	intervene	to	regulate	the	market,	and	lay	down	an
ethical	code	binding	all	self-driving	cars?	Some	lawmakers	will	doubtless	be
thrilled	by	the	opportunity
	to	finally	make	laws	that	are	
always
	followed	to	the
letter.	Other	lawmakers	may	be	alarmed	by	such	unprecedented	and	totalitarian
responsibility.	After	all,	throughout	history	the	limitations	of	law	enforcement
provided	a	welcome	check	on	the	biases,	mistakes	and	excesses	of	lawmakers.	It
was	an	extremely	lucky	thing	that	laws	against	homosexuality	and	against
blasphemy	were	only	partially	enforced.
	Do	we	really	want	a	system	in	which
the	decisions	of	fallible	politicians	become	as	inexorable	as	gravity?
Digital	dictatorships
AI	often	frightens	people	because	they	don’t	trust	the	AI	to	remain	obedient.	We
have	seen	too	many	science-fiction	movies	about	robots	rebelling	against	their
human	masters,	running	amok	in	the	streets	and	slaughtering	everyone.	Yet	the
real	problem	with	robots	is
	exactly	the	opposite.	We	should	fear	them	because
they	will	probably	always	obey	their	masters	and	never	rebel.
There	is	nothing	wrong	with	blind	obedience,	of	course,	as	long	as	the	robots
happen	to	serve	benign	masters.	Even	in	warfare,	reliance	on	killer	robots	could
ensure	that	for	the	first	time	in	history,	the	laws	of	war	would	actually	be	obeyed
on	the	battlefield.	Human	soldiers	are	sometimes
	driven	by	their	emotions	to
murder,	pillage	and	rape	in	violation	of	the	laws	of	war.	We	usually	associate
emotions	with	compassion,	love	and	empathy,	but	in	wartime,	the	emotions	that
take	control	are	all	too	often	fear,	hatred	and	cruelty.	Since	robots	have	no
emotions,	they	could	be	trusted	to	always	adhere	to	the	dry	letter	of	the	military
code,	and	never	be	swayed	by	personal	fears	and
	hatreds.
23
On	16	March	1968	a	company	of	American	soldiers	went	berserk	in	the	South
Vietnamese	village	of	My	Lai,	and	massacred	about	400	civilians.	This	war
crime	resulted	from	the	local	initiative	of	men	who	had	been	involved	in	jungleguerrilla	warfare	for	several	months.	It	did	not	serve	any	strategic	purpose,	and
contravened	both	the	legal	code	and	the	military	policy	of	the	USA.	It	was
	the
fault	of	human	emotions.
24
	If	the	USA	had	deployed	killer	robots	in	Vietnam,	the
massacre	of	My	Lai	would	never	have	occurred.
Nevertheless,	before	we	rush	to	develop	and	deploy	killer	robots,	we	need	to
remind	ourselves	that	the	robots	always	reflect	and	amplify	the	qualities	of	their
code.	If	the	code	is	restrained	and	benign	–	the	robots	will	probably	be	a	huge
improvement	over	the	average
	human	soldier.	Yet	if	the	code	is	ruthless	and
cruel	–	the	results	will	be	catastrophic.	The	real	problem	with	robots	is	not	their
own	artificial	intelligence,	but	rather	the	natural	stupidity	and	cruelty	of	their
human	masters.
In	July	1995	Bosnian	Serb	troops	massacred	more	than	8,000	Muslim
Bosniaks	around	the	town	of	Srebrenica.	Unlike	the	haphazard	My	Lai	massacre,
the	Srebrenica	killings
	were	a	protracted	and	well-organised	operation	that
reflected	Bosnian	Serb	policy	to	‘ethnically	cleanse’	Bosnia	of	Muslims.
25
	If	the
Bosnian	Serbs	had	had	killer	robots	in	1995,	it	would	likely	have	made	the
atrocity	worse	rather	than	better.	Not	one	robot	would	have	had	
a	moment’s
hesitation	carrying	out	whatever	orders	it	received,	and	would	not	have	spared
the	life	of	a	single	Muslim	child
	out	of	feelings	of	compassion,	disgust,	or	mere
lethargy.
A	ruthless	dictator	armed	with	such	killer	robots	will	never	have	to	fear	that
his	soldiers	will	turn	against	him,	no	matter	how	heartless	and	crazy	his	orders.
A	robot	army	would	probably	have	strangled	the	French	Revolution	in	its	cradle
in	1789,	and	if	in	2011	Hosni	Mubarak	had	had	a	contingent	of	killer	robots	he
could	have	unleashed
	them	on	the	populace	without	fear	of	defection.	Similarly,
an	imperialist	government	relying	on	a	robot	army	could	wage	unpopular	wars
without	any	concern	that	its	robots	might	lose	their	motivation,	or	that	their
families	might	stage	protests.	If	the	USA	had	had	killer	robots	in	the	Vietnam
War,	the	My	Lai	massacre	might	have	been	prevented,	but	the	war	itself	could
have	dragged	on	for	many	more
	years,	because	the	American	government	would
have	had	fewer	worries	about	demoralised	soldiers,	massive	anti-war
demonstrations,	or	a	movement	of	‘veteran	robots	against	the	war’	(some
American	citizens	might	still	have	objected	to	the	war,	but	without	the	fear	of
being	drafted	themselves,	the	memory	of	personally	committing	atrocities,	or	the
painful	loss	of	a	dear	relative,	the	protesters	would
	probably	have	been	both	less
numerous	and	less	committed).
26
These	kinds	of	problems	are	far	less	relevant	to	autonomous	civilian	vehicles,
because	no	car	manufacturer	will	maliciously	program	its	vehicles	to	target	and
kill	people.	Yet	autonomous	weapon	systems	are	a	catastrophe	waiting	tohappen,	because	too	many	governments	tend	to	be	ethically	corrupt,	if	not
downright	evil.
The	danger	is
	not	restricted	to	killing	machines.	Surveillance	systems	could	be
equally	risky.	In	the	hands	of	a	benign	government,	powerful	surveillance
algorithms	can	be	the	best	thing	that	ever	happened	to	humankind.	Yet	the	same
Big	Data	algorithms	might	also	empower	a	future	Big	Brother,	so	that	we	might
end	up	with	an	Orwellian	surveillance	regime	in	which	all	individuals	are
monitored	all	the	time.
27
Indeed,	we	might	end	up	with	something	that	even	Orwell	could	barely
imagine:	a	total	surveillance	regime	that	follows	not	just	all	our	external
activities	and	utterances,	but	can	even	go	under	our	skin	to	observe	our	inner
experiences.	Consider	for	example	what	the	Kim	regime	in	North	Korea	might
do	with	the	new	technology.	In	the	future,	each	North	Korean	citizen	might	be
required	to	wear	a	biometric
	bracelet	that	monitors	everything	you	do	and	say	–
as	well	as	your	blood	pressure	and	brain	activity.	By	using	our	growing
understanding	of	the	human	brain,	and	using	the	immense	powers	of	machine
learning,	the	North	Korean	regime	might	be	able	for	the	first	time	in	history	to
gauge	what	each	and	every	citizen	is	thinking	each	and	every	moment.	If	you
look	at	a	picture	of	Kim	Jong-un	and
	the	biometric	sensors	pick	up	the	telltale
signs	of	anger	(higher	blood	pressure,	increased	activity	in	the	amygdala)	–
you’ll	be	in	the	Gulag	tomorrow	morning.
Granted,	due	to	its	isolation	the	North	Korean	regime	might	have	difficulty
developing	the	required	technology	by	itself.	However,	the	technology	might	be
pioneered	in	more	tech-savvy	nations,	and	copied	or	bought	by	the	North
Koreans
	and	other	backward	dictatorships.	Both	China	and	Russia	are	constantly
improving	their	surveillance	tools,	as	are	a	number	of	democratic	countries,
ranging	from	the	USA	to	my	home	country	of	Israel.	Nicknamed	‘the	start-up
nation’,	Israel	has	an	extremely	vibrant	hi-tech	sector,	and	a	cutting-edge	cyber-
security	industry.	At	the	same	time	it	is	also	locked	into	a	deadly	conflict	with
the	Palestinians,
	and	at	least	some	of	its	leaders,	generals	and	citizens	might	well
be	happy	to	create	a	total	surveillance	regime	in	the	West	Bank	as	soon	as	they
have	the	necessary	technology.
Already	today	whenever	Palestinians	make	a	phone	call,	post	something	on
Facebook	or	travel	from	one	city	to	another	they	are	likely	to	be	monitored	by
Israeli	microphones,	cameras,	drones	or	spy	software.	The	gathered
	data	is	then
analysed	with	the	aid	of	Big	Data	algorithms.	This	helps	the	Israeli	security
forces	to	pinpoint	and	neutralise	potential	threats	without	having	to	place	too
many	boots	on	the	ground.	The	Palestinians	may	administer	some	towns	and
villages	in	the	West	Bank,	but	the	Israelis	control	the	sky,	the	airwaves	andcyberspace.	It	therefore	takes	surprisingly	few	Israeli	soldiers	to	effectively
control	about	2.5	million	Palestinians	in	the	West	Bank.
28
In	one	tragicomic	incident	in	October	2017,	a	Palestinian	labourer	posted	to
his	private	Facebook	account	a	picture	of	himself	in	his	workplace,	alongside	a
bulldozer.	Adjacent	to	the	image	he	wrote	‘Good	morning!’	An	automatic
algorithm	made	a	small	error	when	transliterating	the	Arabic	letters.	Instead	of
‘
Ysabechhum!
’	(which	means
	‘Good	morning!’),	the	algorithm	identified	the
letters	as	‘
Ydbachhum!
’	(which	means	‘Kill	them!’).	Suspecting	that	the	man
might	be	a	terrorist	intending	to	use	a	bulldozer	to	run	people	over,	Israeli
security	forces	swiftly	arrested	him.	He	was	released	after	they	realised	that	the
algorithm	made	a	mistake.	But	the	offending	Facebook	post	was	nevertheless
taken	down.	You	can	never	be	too	careful.
29
	What	Palestinians	are	experiencing
today	in	the	West	Bank	might	be	just	a	primitive	preview	to	what	billions	will
eventually	experience	all	over	the	planet.
In	the	late	twentieth	century	democracies	usually	outperformed	dictatorships
because	democracies	were	better	at	data-processing.	Democracy	diffuses	the
power	to	process	information	and	make	decisions	among	many	people	and
institutions,	whereas
	dictatorship	concentrates	information	and	power	in	one
place.	Given	twentieth-century	technology,	it	was	inefficient	to	concentrate	too
much	information	and	power	in	one	place.	Nobody	had	the	ability	to	process	all
the	information	fast	enough	and	make	the	right	decisions.	This	is	part	of	the
reason	why	the	Soviet	Union	made	far	worse	decisions	than	the	United	States,
and	why	the	Soviet	economy
	lagged	far	behind	the	American	economy.
However,	soon	AI	might	swing	the	pendulum	in	the	opposite	direction.	AI
makes	it	possible	to	process	enormous	amounts	of	information	centrally.	Indeed,
AI	might	make	centralised	systems	far	more	efficient	than	diffused	systems,
because	machine	learning	works	better	the	more	information	it	can	analyse.	If
you	
concentrate	all	the	information	relating	to	a
	billion	people	in	one	database,
disregarding	all	privacy	concerns,	you	can	train	much	better	algorithms	than	if
you	respect	individual	privacy	and	have	in	your	database	only	partial
information	on	a	million	people.	For	example,	if	an	authoritarian	government
orders	all	its	citizens	to	have	their	DNA	scanned	and	to	share	all	their	medical
data	with	some	central	authority,	it	would	gain	an	immense
	advantage	in
genetics	and	medical	research	over	societies	in	which	medical	data	is	strictly
private.	The	main	handicap	of	authoritarian	regimes	in	the	twentieth	century	–
the	attempt	to	concentrate	all	information	in	one	place	–	might	become	their
decisive	advantage	in	the	twenty-first	century.
As	algorithms	come	to	know	us	so	well,	authoritarian	governments	could	gain
absolute	control	over	their
	citizens,	even	more	so	than	in	Nazi	Germany,	andresistance	to	such	regimes	might	be	utterly	impossible.	Not	only	will	the	regime
know	exactly	how	you	feel	–	it	could	make	you	feel	whatever	it	wants.	The
dictator	might	not	be	able	to	provide	citizens	with	healthcare	or	equality,	but	he
could	make	them	love	him	and	hate	his	opponents.	Democracy	in	its	present
form	cannot	survive	the	merger	of
	biotech	and	infotech.	Either	democracy	will
successfully	reinvent	itself	in	a	radically	new	form,	or	humans	will	come	to	live
in	‘digital	dictatorships’.
This	will	not	be	a	return	to	the	days	of	Hitler	and	Stalin.	Digital	dictatorships
will	be	as	different	from	Nazi	Germany	as	Nazi	Germany	was	different	from
ancien	régime
	France.	Louis	XIV	was	a	centralising	autocrat,	but	he	did	not
have	the
	technology	to	build	a	modern	totalitarian	state.	He	suffered	no
opposition	to	his	rule,	yet	in	the	absence	of	radios,	telephones	and	trains,	he	had
little	control	over	the	day-to-day	lives	of	peasants	in	remote	Breton	villages,	or
even	of	townspeople	in	the	heart	of	Paris.	He	had	neither	the	will	nor	the	ability
to	establish	a	mass	party,	a	countrywide	youth	movement,	or	a	national
education	system.
30
	It	was	the	new	technologies	of	the	twentieth	century	that
gave	Hitler	both	the	motivation	and	the	
power	to	do	such	things.	We	cannot
predict	what	will	be	the	motivations	and	powers	of	digital	dictatorships	in	2084,
but	it	is	very	unlikely	that	they	will	just	copy	Hitler	and	Stalin.	Those	gearing
themselves	up	to	refight	the	battles	of	the	1930s	might	be	caught	off	their	guard
by	an	attack	from
	a	totally	different	direction.
Even	if	democracy	manages	to	adapt	and	survive,	people	might	become	the
victims	of	new	kinds	of	oppression	and	discrimination.	Already	today	more	and
more	banks,	corporations	and	institutions	are	using	algorithms	to	analyse	data
and	make	decisions	about	us.	When	you	apply	to	your	bank	for	a	loan,	it	is	likely
that	your	application	is	processed	by	an	algorithm	rather
	than	by	a	human.	The
algorithm	analyses	lots	of	data	about	you	and	statistics	about	millions	of	other
people,	and	decides	whether	you	are	reliable	enough	to	give	you	a	loan.	Often,
the	algorithm	does	a	better	job	than	a	human	banker.	But	the	problem	is	that	if
the	algorithm	discriminates	against	some	people	unjustly,	it	is	difficult	to	know
that.	If	the	bank	refuses	to	give	you	a	loan,	and	you
	ask	‘Why?’,	the	bank	replies
‘The	algorithm	said	no.’	You	ask	‘Why	did	the	algorithm	say	no?	What’s	wrong
with	me?’,	and	the	bank	replies	‘We	don’t	know.	No	human	understands	this
algorithm,	because	it	is	based	on	advanced	machine	learning.	But	we	trust	our
algorithm,	so	we	won’t	give	you	a	loan.’
31
When	discrimination	is	directed	against	entire	groups,	such	as	women	or	black
people,	these	groups
	can	organise	and	protest	against	their	collective
discrimination.	But	now	an	algorithm	might	discriminate	against	you	personally,
and	you	have	no	idea	why.	Maybe	the	algorithm	found	something	in	your	DNA,your	personal	history	or	your	Facebook	account	that	it	does	not	like.	The
algorithm	discriminates	against	you	not	because	you	are	a	woman,	or	an	African
American	–	but	because	you	are	you.	There
	is	something	specific	about	you	that
the	algorithm	does	not	like.	You	don’t	know	what	it	is,	and	even	if	you	knew,
you	cannot	organise	with	other	people	to	protest,	because	there	are	no	other
people	suffering	the	exact	same	prejudice.	It	is	just	you.	Instead	of	just	collective
discrimination,	in	the	twenty-first	century	we	might	face	a	growing	problem	of
individual	discrimination.
32
At	the	highest
	levels	of	authority,	we	will	probably	retain	human	figureheads,
who	will	give	us	the	illusion	that	the	algorithms	are	only	advisors,	and	that
ultimate	authority	is	still	in	human	hands.	We	will	not	appoint	an	AI	to	be	the
chancellor	of	Germany	or	the	CEO	of	Google.	However,	the	decisions	taken	by
the	chancellor	and	the	CEO	will	be	shaped	by	AI.	The	chancellor	could	still
choose	between	several
	different	options,	but	all	these	options	will	be	the
outcome	of	Big	Data	analysis,	and	they	will	reflect	the	way	AI	views	the	world
more	than	the	way	humans	view	it.
To	take	an	analogous	example,	today	politicians	all	over	the	world	can	choose
between	several	different	economic	policies,	but	in	almost	all	cases	the	various
policies	on	offer	reflect	a	capitalist	outlook	on	economics.	The	politicians
	have
an	illusion	of	choice,	but	the	really	important	decisions	have	already	been	made
much	earlier	by	the	economists,	bankers	and	business	people	who	shaped	the
different	options	in	the	menu.	Within	a	couple	of	decades,	politicians	might	find
themselves	choosing	from	a	menu	written	by	AI.
Artificial	intelligence	and	natural	stupidity
One	piece	of	good	news	is	that	at	least	in	the	next	few	decades,
	we	won’t	have	to
deal	with	the	full-blown	science-fiction	nightmare	of	AI	gaining	consciousness
and	deciding	to	enslave	or	wipe	out	humanity.	We	will	increasingly	rely	on
algorithms	to	make	decisions	for	us,	but	it	is	unlikely	that	the	algorithms	will
start	to	consciously	manipulate	us.	They	won’t	have	any	consciousness.
Science	fiction	tends	to	confuse	intelligence	with	consciousness,	and	assume
that	in	order	to	match	or	surpass	human	
intelligence,	computers	will	have	to
develop	consciousness.	The	basic	plot	of	almost	all	movies	and	novels	about	AI
revolves	around	the	magical	moment	when	a	computer	or	a	robot	gains
consciousness.	Once	that	happens,	either	the	human	hero	falls	in	love	with	the
robot,	or	the	robot	tries	to	kill	all	the	humans,	or	both	things	happensimultaneously.
But
	in	reality,	there	is	no	reason	to	assume	that	artificial	intelligence	will	gain
consciousness,	because	intelligence	and	consciousness	are	very	different	things.
Intelligence	is	the	ability	to	solve	problems.	Consciousness	is	the	ability	to	feel
things	such	as	pain,	joy,	love	and	anger.	We	tend	to	confuse	the	two	because	in
humans	and	other	mammals	intelligence	goes	hand	in	hand	with	consciousness.
Mammals	solve	most	problems	by	feeling	things.	Computers,	however,	solve
problems	in	a	very	different	way.
There	are	simply	several	different	paths	leading	to	high	intelligence,	and	only
some	of	these	paths	involve	gaining	consciousness.	Just	as	airplanes	fly	faster
than	birds	without	ever	developing	feathers,	so	computers	may	come	to	solve
problems	much	better	than	mammals	without	ever	developing
	feelings.	True,	AI
will	have	to	analyse	human	feelings	accurately	in	order	to	treat	human	illnesses,
identify	human	terrorists,	recommend	human	mates	and	navigate	a	street	full	of
human	pedestrians.	But	it	could	do	so	without	having	any	feelings	of	its	own.	An
algorithm	does	not	need	to	feel	joy,	anger	or	fear	in	order	to	recognise	the
different	biochemical	patterns	of	joyful,	angry	or	frightened
	apes.
Of	course,	it	is	not	absolutely	impossible	that	AI	will	develop	feelings	of	its
own.	We	still	don’t	know	enough	about	consciousness	to	be	sure.	In	general,
there	are	three	possibilities	we	need	to	consider:
	
1.	
Consciousness	is	somehow	linked	to	organic	biochemistry	in	such	a	way
that	it	will	never	be	possible	to	create	consciousness	in	non-organic
systems.
2.	
Consciousness	is	not	linked	to	organic	biochemistry,	but	it	is	linked	to
intelligence	in	such	a	way	that	computers	could	develop	consciousness,	and
computers	will	
have	to
	develop	consciousness	if	they	are	to	pass	a	certain
threshold	of	intelligence.
3.	
There	are	no	essential	links	between	consciousness	and	either	organic
biochemistry	or	high	intelligence.	Hence	computers	might	develop
consciousness	–	but	not	necessarily.	They	could	become	super-intelligent
while	still	having	zero	consciousness.
At	our	present	state	of	knowledge,	we	cannot	rule	out	any	of	these	options.
Yet	precisely	because	we	know	so	little	about	consciousness,	it	seems	unlikely
that	we	could	program	conscious	computers	any	time	soon.	Hence	despite	the
immense	power	of	artificial	intelligence,	for	the	foreseeable	future	its	usage	will
continue	to
	depend	to	some	extent	on	human	consciousness.The	danger	is	that	if	we	invest	too	much	in	developing	AI	and	too	little	in
developing	human	consciousness,	the	very	sophisticated	artificial	intelligence	of
computers	might	only	serve	to	empower	the	natural	stupidity	of	humans.	We	are
unlikely	to	face	a	robot	rebellion	in	the	coming	decades,	but	we	might	have	to
deal	with	hordes	of	bots	who	know
	how	to	press	our	emotional	buttons	better
than	our	mother,	and	use	this	uncanny	ability	to	try	and	sell	us	something	–	be	it
a	car,	a	politician,	or	an	entire	ideology.	The	bots	could	identify	our	deepest
fears,	hatreds	and	cravings,	and	use	these	inner	leverages	against	us.	We	have
already	been	given	a	foretaste	of	this	in	recent	elections	and	referendums	across
the	world,	when	hackers	have	learned
	how	to	manipulate	individual	voters	by
analysing	data	about	them	and	exploiting	their	existing	prejudices.
33
	While
science-fiction	thrillers	are	drawn	to	dramatic	apocalypses	of	fire	and	smoke,	in
reality	we	might	be	facing	a	banal	apocalypse	by	clicking.
To	avoid	such	outcomes,	for	every	dollar	and	every	minute	we	invest	in
improving	artificial	intelligence,	it	would	be	wise	to	
invest	a	dollar
	and	a	minute
in	advancing	human	consciousness.	Unfortunately,	at	present	we	are	not	doing
much	to	research	and	develop	human	consciousness.	We	are	researching	and
developing	human	abilities	mainly	according	to	the	immediate	needs	of	the
economic	and	political	system,	rather	than	according	to	our	own	long-term	needs
as	conscious	beings.	My	boss	wants	me	to	answer	emails	as	quickly	as	possible,
but
	he	has	little	interest	in	my	ability	to	taste	and	appreciate	the	food	I	am	eating.
Consequently,	I	check	my	emails	even	during	meals,	while	losing	the	ability	to
pay	attention	to	my	own	sensations.	The	economic	system	pressures	me	to
expand	and	diversify	my	investment	portfolio,	but	it	gives	me	zero	incentives	to
expand	and	diversify	my	compassion.	So	I	strive	to	understand	the	mysteries	of
the
	stock	exchange,	while	making	far	less	effort	to	understand	the	deep	causes	of
suffering.
In	this,	humans	are	similar	to	other	domesticated	animals.	We	have	bred
docile	cows	that	produce	enormous	amounts	of	milk,	but	are	otherwise	far
inferior	to	their	wild	ancestors.	They	are	less	agile,	less	curious	and	less
resourceful.
34
	We	are	now	creating	tame	humans	that	produce	enormous	amounts
of	data
	and	function	as	very	efficient	chips	in	a	huge	data-processing
mechanism,	but	these	data-cows	hardly	maximise	the	human	potential.	Indeed
we	have	no	idea	what	the	full	human	potential	is,	because	we	know	so	little
about	the	human	mind.	And	yet	we	hardly	invest	much	in	exploring	the	human
mind,	and	instead	focus	on	increasing	the	speed	of	our	Internet	connections	and
the	efficiency	of	our	Big	Data
	algorithms.	If	we	are	not	careful,	we	will	end	up
with	downgraded	humans	misusing	upgraded	computers	to	wreak	havoc	on
themselves	and	on	the	world.Digital	dictatorships	are	not	the	only	danger	awaiting	us.	Alongside	liberty,
the	liberal	order	has	also	set	great	store	by	the	value	of	equality.	Liberalism
always	cherished	political	equality,	and	it	gradually	came	to	realise	that
economic	equality
	is	almost	as	important.	For	without	a	social	safety	net	and	a
modicum	of	economic	equality,	liberty	is	meaningless.	But	just	as	Big	Data
algorithms	might	extinguish	liberty,	they	might	simultaneously	create	the	most
unequal	societies	that	ever	existed.	All	wealth	and	power	might	be	concentrated
in	the	hands	of	a	tiny	elite,	while	most	people	will	suffer	not	from	exploitation,
but	from	something
	far	worse	–	irrelevance.4
EQUALITY
Those	who	own	the	data	own	the	future
In	the	last	few	decades,	people	all	over	the	world	were	told	that	humankind	is	on
the	path	to	equality,	and	that	globalisation	and	new	technologies	will	help	us	get
there	sooner.	In	reality,	the	twenty-first	century	might	create	the	most	unequal
societies	in	history.	Though	globalisation	and	the	Internet	bridge	the	gap
between	countries,	they	threaten
	to	enlarge	the	rift	between	classes,	and	just	as
humankind	seems	about	to	achieve	global	unification,	the	species	itself	might
divide	into	different	biological	castes.
Inequality	goes	back	to	the	Stone	Age.	Thirty	thousand	years	ago,	hunter-
gatherer	bands	buried	some	members	in	sumptuous	graves	replete	with
thousands	of	ivory	beads,	bracelets,	jewels	and	art	objects,	while	other	members
had	to
	settle	for	a	bare	hole	in	the	ground.	Nevertheless,	ancient	hunter-gatherer
bands	were	still	more	egalitarian	than	any	subsequent	human	society,	because
they	had	very	little	property.	Property	is	a	prerequisite	for	long-term	inequality.
Following	the	Agricultural	Revolution,	property	multiplied	and	with	it
inequality.	As	humans	gained	ownership	of	land,	animals,	plants	and	tools,	rigid
hierarchical
	societies	emerged,	in	which	small	elites	monopolised	most	wealth
and	power	for	generation	after	generation.	Humans	came	to	accept	this
arrangement	as	natural	and	even	divinely	ordained.	Hierarchy	was	not	just	the
norm,	but	also	the	ideal.	How	can	there	be	order	without	a	clear	
hierarchy
between	aristocrats	and	commoners,	between	men	and	women,	or	between
parents	and	children?	Priests,	philosophers
	and	poets	all	over	the	world	patiently
explained	that	just	as	in	the	human	body	not	all	members	are	equal	–	the	feet
must	obey	the	head	–	so	also	in	human	society	equality	will	bring	nothing	but
chaos.
In	the	late	modern	era,	however,	equality	became	an	ideal	in	almost	all	human
societies.	It	was	partly	due	to	the	rise	of	the	new	ideologies	of	communism	andliberalism.	But	it	was	also	due	to
	the	Industrial	Revolution,	which	made	the
masses	more	important	than	ever	before.	Industrial	economies	relied	on	masses
of	common	workers,	while	industrial	armies	relied	on	masses	of	common
soldiers.	Governments	in	both	democracies	and	dictatorships	invested	heavily	in
the	health,	education	and	welfare	of	the	masses,	because	they	needed	millions	of
healthy	labourers	to	operate	the	production	lines
	and	millions	of	loyal	soldiers	to
fight	in	the	trenches.
Consequently,	the	history	of	the	twentieth	century	revolved	to	a	large	extent
around	the	reduction	of	inequality	between	classes,	races	and	genders.	Though
the	world	of	the	year	2000	still	had	its	share	of	hierarchies,	it	was	nevertheless	a
far	more	equal	place	than	the	world	of	1900.	In	the	first	years	of	the	twenty-first
century	people
	expected	that	the	egalitarian	process	would	continue	and	even
accelerate.	In	particular,	they	hoped	that	globalisation	would	spread	economic
prosperity	throughout	the	world,	and	that	as	a	result	people	in	India	and	Egypt
will	come	to	enjoy	the	same	opportunities	and	privileges	as	people	in	Finland
and	Canada.	An	entire	generation	grew	up	on	this	promise.
Now	it	seems	that	this	promise	might	not
	be	fulfilled.	Globalisation	has
certainly	benefited	large	segments	of	humanity,	but	there	are	signs	of	growing
inequality	both	between	and	within	societies.	Some	groups	increasingly
monopolise	the	fruits	of	globalisation,	while	billions	are	left	behind.	Already
today,	the	richest	1	per	cent	owns	half	the	world’s	wealth.	Even	more
alarmingly,	the	richest	hundred	people	together	own	more	than	the
	poorest	4
billion.
1
This	could	get	far	worse.	As	explained	in	earlier	chapters,	the	rise	of	AI	might
eliminate	the	economic	value	and	political	power	of	most	humans.	At	the	same
time,	improvements	in	biotechnology	might	make	it	possible	to	translate
economic	inequality	into	biological	inequality.	The	super-rich	will	finally	have
something	really	worthwhile	to	do	with	their	stupendous	wealth.
	While	hitherto
they	could	buy	little	more	than	status	symbols,	soon	they	might	be	able	to	buy
life	itself.	If	new	treatments	for	extending	life	and	for	upgrading	physical	and
cognitive	abilities	prove	to	be	expensive,	humankind	might	split	into	biological
castes.
Throughout	history	the	rich	and	the	aristocracy	always	imagined	that	they	had
superior	skills	to	everybody	else,	which	is	why	they
	were	in	control.	As	far	as
we	can	tell,	this	wasn’t	true.	The	average	duke	wasn’t	more	talented	than	the
average	peasant	–	he	owed	his	superiority	only	to	unjust	legal	and	economic
discrimination.	However,	by	2100	the	rich	might	really	be	more	talented,	more
creative	and	more	intelligent	than	the	slum-dwellers.	Once	a	real	gap	in	ability
opens	between	the	rich	and	the	poor,	it	will	become	almost	impossible
	to	closeit.	If	the	rich	use	their	superior	abilities	to	enrich	themselves	further,	and	if	more
money	can	buy	them	enhanced	bodies	and	brains,	with	time	the	gap	will	only
widen.	By	2100,	the	richest	1	per	cent	might	own	not	merely	most	of	the	world’s
wealth,	but	also	most	of	the	world’s	beauty,	creativity	and	health.
The	two	processes	together	–	bioengineering	coupled	with	the	rise	of	AI	–
might
	therefore	result	in	the	separation	of	humankind	into	a	small	class	of
superhumans	and	a	massive	underclass	of	useless	
Homo	sapiens
.	To	make	an
already	ominous	situation	even	worse,	as	the	masses	lose	their	economic
importance	and	political	power,	the	state	might	lose	at	least	some	of	the
incentive	to	invest	in	their	health,	education	and	welfare.	It’s	very	dangerous	to
be	redundant.	The	future
	of	the	masses	will	then	depend	on	the	goodwill	of	a
small	elite.	Maybe	there	is	goodwill	for	a	few	decades.	But	in	a	time	of	crisis	–
like	climate	catastrophe	–	it	
would	be	very	tempting	and	easy	to	toss	the
superfluous	people	overboard.
In	countries	such	as	France	and	New	Zealand,	with	a	long	tradition	of	liberal
beliefs	and	welfare-state	practices,	perhaps	the	elite	will	go	on	taking	care	of
	the
masses	even	when	it	doesn’t	need	them.	In	the	more	capitalist	USA,	however,
the	elite	might	use	the	first	opportunity	to	dismantle	what’s	left	of	the	American
welfare	state.	An	even	bigger	problem	looms	in	large	developing	countries	like
India,	China,	South	Africa	and	Brazil.	There,	once	common	people	lose	their
economic	value,	inequality	might	skyrocket.
Consequently,	instead	of	globalisation
	resulting	in	global	unity,	it	might
actually	result	in	‘speciation’:	the	divergence	of	humankind	into	different
biological	castes	or	even	different	species.	Globalisation	will	unite	the	world
horizontally	by	erasing	national	borders,	but	it	will	simultaneously	divide
humanity	vertically.	Ruling	oligarchies	in	countries	as	diverse	as	the	United
States	and	Russia	might	merge	and	make	common	cause
	against	the	mass	of
ordinary	Sapiens.	From	this	perspective,	current	populist	resentment	of	‘the
elites’	is	well	founded.	If	we	are	not	careful,	the	grandchildren	of	Silicon	Valley
tycoons	and	Moscow	billionaires	might	become	a	superior	species	to	the
grandchildren	of	Appalachian	hillbillies	and	Siberian	villagers.
In	the	long	run,	such	a	scenario	might	even	de-globalise	the	world,	as	the
upper
	caste	congregates	inside	a	self-proclaimed	‘civilisation’	and	builds	walls
and	moats	to	separate	it	from	the	hordes	of	‘barbarians’	outside.	In	the	twentieth
century,	industrial	civilisation	depended	on	the	‘barbarians’	for	cheap	labour,
raw	materials	and	markets.	Therefore	it	conquered	and	absorbed	them.	But	in	the
twenty-first	century,	a	post-industrial	civilisation	relying	on	AI,	bioengineering
and	nanotechnology	might	be	far	more	self-contained	and	self-sustaining.	Not
just	entire	classes,	but	entire	countries	and	continents	might	become	irrelevant.Fortifications	guarded	by	drones	and	robots	might	separate	the	self-proclaimed
civilised	zone,	where	cyborgs	fight	
one	another	with	logic	bombs,	from	the
barbarian	lands	where	feral	humans	fight	one	another	with	machetes	and
Kalashnikovs.
Throughout	this	book,	I	often	use	the	first	person	plural	to	speak	about	the
future	of	humankind.	I	talk	about	what	‘we’	need	to	do	about	‘our’	problems.
But	maybe	there	are	no	‘we’.	Maybe	one	of	‘our’	biggest	problems	is	that
different	human	groups	have	completely	different	futures.	Maybe	in	some	parts
of	the	world	you	should	teach	your	kids	to	write	computer	code,	while	in	others
you	had	better
	teach	them	to	draw	fast	and	shoot	straight.
Who	owns	the	data?
If	we	want	to	prevent	the	concentration	of	all	wealth	and	power	in	the	hands	of	a
small	elite,	the	key	is	to	regulate	the	ownership	of	data.	In	ancient	times	land
was	the	most	important	asset	in	the	world,	politics	was	a	struggle	to	control	land,
and	if	too	much	land	became	concentrated	in	too	few	hands	–	society	split	into
aristocrats
	and	commoners.	In	the	modern	era	machines	and	factories	became
more	important	than	land,	and	political	struggles	focused	on	controlling	these
vital	means	of	production.	If	too	many	of	the	machines	became	concentrated	in
too	few	hands	–	society	split	into	capitalists	and	proletarians.	In	the	twenty-first
century,	however,	data	will	eclipse	both	land	and	machinery	as	the	most
important	asset,
	and	politics	will	be	a	struggle	to	control	the	flow	of	data.	If	data
becomes	concentrated	in	too	few	hands	–	humankind	will	split	into	different
species.
The	race	to	obtain	the	data	is	already	on,	headed	by	data-giants	such	as
Google,	Facebook,	Baidu	and	Tencent.	So	far,	many	of	these	giants	seem	to
have	adopted	the	business	model	of	‘attention	merchants’.
2
	They	capture	our
attention	by	providing
	us	with	free	information,	services	and	entertainment,	and
they	then	resell	our	attention	to	advertisers.	Yet	the	data-giants	probably	aim	far
higher	than	any	previous	attention	merchant.	Their	true	business	isn’t	to	sell
advertisements	at	all.	Rather,	by	capturing	our	
attention	they	manage	to
accumulate	immense	amounts	of	data	about	us,	which	is	worth	more	than	any
advertising	revenue.	We	aren’t
	their	customers	–	we	are	their	product.
In	the	medium	term,	this	data	hoard	opens	a	path	to	a	radically	different
business	model	whose	first	victim	will	be	the	advertising	industry	itself.	The
new	model	is	based	on	transferring	authority	from	humans	to	algorithms,including	the	authority	to	choose	and	buy	things.	Once	algorithms	choose	and
buy	things	for	us,	the	traditional	advertising	industry
	will	go	bust.	Consider
Google.	Google	wants	to	reach	a	point	where	we	can	ask	it	
anything
,	and	get	the
best	answer	in	the	world.	What	will	happen	once	we	can	ask	Google,	‘Hi
Google,	based	on	everything	you	know	about	cars,	and	based	on	everything	you
know	about	me	(including	my	needs,	my	habits,	my	views	on	global	warming,
and	even	my	opinions	about	Middle	Eastern	politics)	–	what	is	the	best
	car	for
me?’	If	Google	can	give	us	a	good	answer	to	that,	and	if	we	learn	by	experience
to	trust	Google’s	wisdom	instead	of	our	own	easily	manipulated	feelings,	what
could	possibly	be	the	use	of	car	advertisements?
3
In	the	longer	term,	by	bringing	together	enough	data	and	enough	computing
power,	the	data-giants	could	hack	the	deepest	secrets	of	life,	and	then	use	this
knowledge	not	just	to	make
	choices	for	us	or	manipulate	us,	but	also	to	re-
engineer	organic	life	and	to	create	inorganic	life	forms.	Selling	advertisements
may	be	necessary	to	sustain	the	giants	in	the	short	term,	but	they	often	evaluate
apps,	products	and	companies	according	to	the	data	they	harvest	rather	than
according	to	the	money	they	generate.	A	popular	app	may	lack	a	business	model
and	may	even	lose	money	in	the	short
	term,	but	as	long	as	it	sucks	data,	it	could
be	worth	billions.
4
	Even	if	you	don’t	know	how	to	cash	in	on	the	data	today,	it	is
worth	having	it	because	it	might	hold	the	key	to	controlling	and	shaping	life	in
the	future.	I	don’t	know	for	certain	that	the	data-giants	explicitly	think	about	it	in
such	terms,	but	their	actions	indicate	that	they	value	the	accumulation	of	data
more	than	mere	dollars
	and	cents.
Ordinary	humans	will	find	it	very	difficult	to	resist	this	process.	At	present,
people	are	happy	to	give	away	their	most	valuable	asset	–	their	personal	data	–	in
exchange	for	free	email	services	and	funny	cat	videos.	It	is	a	bit	like	African	and
Native	American	tribes	who	unwittingly	sold	entire	countries	to	European
imperialists	in	exchange	for	colourful	beads	and	cheap	trinkets.
	If,	later	on,
ordinary	people	decide	to	try	and	block	the	flow	of	data,	they	might	find	it
increasingly	difficult,	especially	as	they	might	come	to	rely	on	the	network	for
all	their	decisions,	and	even	for	their	healthcare	and	physical	survival.
Humans	and	machines	might	merge	so	completely	that	humans	will	not	be
able	to	survive	at	all	if	they	are	disconnected	from	the	network.	They	will	be
connected	from	the	womb,	and	if	later	in	life	you	choose	to	disconnect,
insurance	agencies	might	refuse	to	insure	you,	employers	might	refuse	to	employ
you,	and	healthcare	services	might	refuse	to	take	care	of	you.	In	the	big	battle
between	health	and	privacy,	health	is	likely	to	win	hands	down.
As	more	and	more	data	flows	from	your	body	and	brain	to	the	smart	machines
via	the	biometric	sensors,
	it	will	become	easy	for	corporations	and	governmentagencies	to	know	you,	manipulate	you,	and	make	decisions	on	your	behalf.	Even
more	importantly,	they	could	decipher	the	deep	mechanisms	of	all	bodies	and
brains,	and	thereby	gain	the	power	to	engineer	life.	If	we	want	to	prevent	a	small
elite	from	monopolising	such	godlike	powers,	and	if	we	want	to	prevent
humankind	from	splitting	into	biological
	castes,	the	key	question	is:	who	owns
the	data?	Does	the	data	about	my	DNA,	my	brain	and	my	life	belong	to	me,	to
the	government,	to	a	corporation,	or	to	the	human	collective?
Mandating	governments	to	nationalise	the	data	will	probably	curb	the	power
of	big	corporations,	but	it	may	also	result	in	creepy	digital	dictatorships.
Politicians	are	a	bit	like	musicians,	and	the	instrument	they	play
	on	is	the	human
emotional	and	biochemical	system.	They	give	a	speech	–	and	there	is	a	wave	of
fear	in	the	country.	They	tweet	–	and	there	is	an	explosion	of	hatred.	
I	don’t
think	we	should	give	these	musicians	a	more	sophisticated	instrument	to	play	on.
Once	politicians	can	press	our	emotional	buttons	directly,	generating	anxiety,
hatred,	joy	and	boredom	at	will,	politics	will	become	a	mere	emotional
	circus.
As	much	as	we	should	fear	the	power	of	big	corporations,	history	suggests	that
we	are	not	necessarily	better	off	in	the	hands	of	over-mighty	governments.	As	of
March	2018,	I	would	prefer	to	give	my	data	to	Mark	Zuckerberg	than	to
Vladimir	Putin	(though	the	Cambridge	Analytica	scandal	revealed	that	perhaps
there	isn’t	much	of	a	choice	here,	as	any	data	entrusted	to	Zuckerberg	may	well
find	its	way	to	Putin).
Private	ownership	of	one’s	own	data	may	sound	more	attractive	than	either	of
these	options,	but	it	is	unclear	what	it	actually	means.	We	have	had	thousands	of
years	of	experience	in	regulating	the	ownership	of	land.	We	know	how	to	build	a
fence	around	a	field,	place	a	guard	at	the	gate,	and	control	who	can	go	in.	Over
the	past	two	centuries	we	have	become	extremely	sophisticated
	in	regulating	the
ownership	of	industry	–	thus	today	I	can	own	a	piece	of	General	Motors	and	a	bit
of	Toyota	by	buying	their	shares.	But	we	don’t	have	much	experience	in
regulating	the	ownership	of	data,	which	is	inherently	a	far	more	difficult	task,
because	unlike	land	and	machines,	data	is	everywhere	and	nowhere	at	the	same
time,	it	can	move	at	the	speed	of	light,	and	you	can	create	as
	many	copies	of	it	as
you	want.
So	we	had	better	call	upon	our	lawyers,	politicians,	philosophers	and	even
poets	to	turn	their	attention	to	this	conundrum:	how	do	you	regulate	the
ownership	of	data?	This	may	well	be	the	most	important	political	question	of	our
era.	If	we	cannot	answer	this	question	soon,	our	sociopolitical	system	might
collapse.	People	are	already	sensing	the	coming	cataclysm.
	Perhaps	this	is	why
citizens	all	over	the	world	are	losing	faith	in	the	liberal	story,	which	just	a
decade	ago	seemed	irresistible.How,	then,	do	we	go	forward	from	here,	and	how	do	we	cope	with	the
immense	challenges	of	the	biotech	and	infotech	revolutions?	Perhaps	the	very
same	scientists	and	entrepreneurs	
who	disrupted	the	world	in	the	first	place
could	engineer	some	technological	solution?
	For	example,	might	networked
algorithms	form	the	scaffolding	for	a	global	human	community	that	could
collectively	own	all	the	data	and	oversee	the	future	development	of	life?	As
global	inequality	rises	and	social	tensions	increase	around	the	world,	perhaps
Mark	Zuckerberg	could	call	upon	his	2	billion	friends	to	join	forces	and	do
something	together?